nrow(verbs)
x = c(1,1,1,1,1,2,2,3,3,3,3,3,3,3,3,3,4,4,5,5,5)
y = c(1,1,1,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,5,5)
plot(x, y)
abline(lm(y ~ x), col = "red")
set.seed(88)
x = rnorm(n = 100) * runif(n = 100)
x
x = rnorm(n = 100) * runif(n = 100)
x
set.seed(88)
x = rnorm(n = 100) * runif(n = 100)
x
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
# [1] 0.02286492 11.63822827
# Check the mean and SD of the "sample"
mean(x.noi) 	#
sd(x.noi) 	#
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = sd.mean)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = nums.sd)
Now, we can generate the density plot of our sample distribution with nums and add the density information of nums (i.e., nums.d) obtained from a corresponding normal distribution to make our comparison, which is visualized in the figure below.
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = nums.sd)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15)
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15)
)
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
set.seed(87) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(86) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(85) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(1) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
qqnorm(nums.noi, main="Normal Q-Q Plot: nums.noi")
qqline(nums.noi, col="red")	# Add a line of "perfect correlation"
library(tidyverse)
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/cou
rseUtil.R")
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
wordRT = tibble(loadCourseCSV(year = 2024, topic = "3_Data", file = "wordRT.csv"))
wordRT
?gather
wordRT %>% gather(Word, "Gender", "RT")
stocks <- tibble(
time = as.Date("2009-01-01") + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
gather(stocks, "stock", "price", -time)
stocks %>% gather("stock", "price", -time)
sticks
stocks
wordRT %>% gather("Gender", "RT")
wordRT %>% gather("Gender", "RT", -Word)
wordRT %>% gather("Word", "Gender", "RT")
wordRT %>% pivot_longer(c("Gender", "RT"))
wordRT %>% pivot_longer(c("Male", "Female"))
wordRT %>% pivot_longer(c("Male", "Female"), names_to = "Gender", values_to = "RT")
jabberwocky.wd = loadCourseCSV(2024, "3_Data", "jabberwocky_words.txt")
head(jabberwocky.wd)
jabberwocky.wd = tibble(loadCourseCSV(2024, "3_Data", "jabberwocky_words.txt"))
jabberwocky.wd %>% count(Word)
?count
jabberwocky.wd %>% count(Word, name = "Freq")
jabberwocky.wd %>% count(Word, name = "Freq", sort = T)
strs = c("This is not a long sentence.")
strs.token = strsplit(strs, " ")
strs.token
strs.token = unlist(strsplit(strs, " "))
strs.token
strs.token = strsplit(strs, " ")
strs.token[1]
strs.token[[1]]
strs.token[[1]][]
strs.token[[1]][1]
set.seed(100) # Set the random seed
# Create a for loop in which n starts with 1 and increases by 1 after each cycle.
# The loop stops after the end of a cycle in which n becomes 50.
for(n in 1:20) {
# Randomly sample one value from a normal distribution using rnorm().
# Since the distribution has a mean of 0 and an sd of 1, which are the default
# values for the corresponding parameters in rnorm(), you don't have to specify
# the two parameters in this line. The randomly selected value is stored as
# "val".
val = rnorm(n = 1)
print(val) # Just print out the random value in each cycle.
}
1/20
library(ggplot2)
?geom_boxplot()
sam = exp(rnorm(100, 10, 2))
mean(sam - mean(sam))
range(sam)
mean(sam)
dbinom(4, 4, 0.5)
qnorm(0.025)
qnorm(0.025, mean = 300, sd = 40)
qnorm(0.025, mean = 300, sd = 40, lower.tail = F)
p0 = dbinom(x = 0, size = 3, prob = 0.5)
p1 = dbinom(x = 1, size = 3, prob = 0.5)	# 得出剛好1個正面的機率
p2 = dbinom(x = 2, size = 3, prob = 0.5)	# 得出剛好2個正面的機率
p3 = dbinom(x = 3, size = 3, prob = 0.5)	# 得出剛好3個正面的機率
pbinom(q = 2, size = 3, prob = 0.5)
pbinom(q = (3 - 2), size = 3, prob = 0.5)
pbinom(q = 2, size = 3, prob = 0.5, lower.tail = F)
pbinom(q = 1, size = 3, prob = 0.5, lower.tail = F)
?aov
?anova
library(car)
?Anova
# Load the course script
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
# Load the Myers' (2015) clean data set to revisit the test of equal variance
# (aka F-test)
Myers.clean = loadCourseCSV(2024, "5_ANOVA", "MyersClean.csv")
# Extract the logRT of the two experiment sessions to test if the two samples
# have an equal variance
s1.rt = Myers.clean[Myers.clean$Session == 1,]$logRT
s2.rt = Myers.clean[Myers.clean$Session == 2,]$logRT
# Check the report of the F-test generated by var.test(); check the Unit 5
# handout for detailed explanations.
var.test(s1.rt, s2.rt)
# F-test formula: s2x / s2y
var(s1.rt) / var(s2.rt)
# Get the p-value from an F distribution with two dfs derived from the
# numerator and denominator samples. The F value is higher than 1, which is the
# peak of an F distribution, so get an upper tail p-value first.
pf(q = 1.160577, df1 = 6750, df2 = 7200, lower.tail = F)
# Double the one-tailed p to get a two-tailed p, because the null hypothesis
# in an F-test is that the two variances are the same, which means that the
# alternative hypothesis is that the numerator is higher/lower than the
# denominator.
pf(q = 1.160577, df1 = 6750, df2 = 7200, lower.tail = F) * 2
# Extend the F-test to a one-way independent-measures ANOVA
# Check the Unit 5 handout for the explanations of "one-way",
# "independent measures", and its null/alternative hypothesis.
# Check the Unit 5 handout for the detailed introduction to Saito & Lyster's
# (2012) study
sl.sim = loadCourseCSV(2024, "5_ANOVA", "SaitoLysterSim.csv")
# Use the y ~ x syntax (explain the dependent variable y with the independent
# variable/factor x) to build an ANOVA model and fit the model to the data
sl.sim.aov = aov(formula = rF3 ~ Group, data = sl.sim)
# Get the analysis summary
summary(sl.sim.aov)
# Validate the F-value: between-sample Mean Sq / within-sample Mean Sq (aka MSE)
5345500 / 107131
# Manually calculate SS, F, and p-value in one-way independent-measures ANOVA
# The global mean: The average value of the entire sample
mean.global = mean(sl.sim$rF3)
# Extract the three subsets based on Group
sl.sim.control = subset(sl.sim, Group == "Control")
sl.sim.ffi = subset(sl.sim, Group == "FFI")
sl.sim.fficf = subset(sl.sim, Group == "FFI+CF")
# Calculate the three sample means
mean.control = mean(sl.sim.control$rF3)
mean.ffi = mean(sl.sim.ffi$rF3)
mean.fficf = mean(sl.sim.fficf$rF3)
# Calculate the size of each sample
control.size = nrow(sl.sim.control)
ffi.size = nrow(sl.sim.ffi)
fficf.size = nrow(sl.sim.fficf)
# Calculate the between-sample sum of squares (SS-between): The squared differences
# between individual sample means and the global mean
ss.between = control.size * (mean.control - mean.global) ^ 2 +
ffi.size * (mean.ffi - mean.global) ^ 2 +
fficf.size * (mean.fficf - mean.global) ^ 2
# df-between is the number of levels in the only fixed factor (aka independent
# variable) minus 1
df.between = 3 - 1
# Between-sample mean squared difference, or MS. The interesting variance.
ss.between / df.between
# Calculate the within-sample sum of squares (SS-within): The squared differences
# between individual data points in each sample and their sample mean.
ss.control = sum((sl.sim.control$rF3 - mean.control) ^ 2)
ss.ffi = sum((sl.sim.ffi$rF3 - mean.ffi) ^ 2)
ss.fficf = sum((sl.sim.fficf$rF3 - mean.fficf) ^ 2)
ss.within = ss.control + ss.ffi + ss.fficf
# df-within is the sum of each sample size minus 1
df.within = control.size - 1 + ffi.size - 1 + fficf.size - 1
# Get within-sample mean squared difference: The boring variance.
ss.within / df.within
# Get the one-tailed p-value using pf() based on the F-value and the two dfs.
# We only need to calculate the UPPER TAIL p-value because the only thing we
# want to know is whether the interesting variance is significantly higher than
# the boring variance (i.e., F is significantly higher than 1).
pf(q = (ss.between / df.between) / (ss.within / df.within), df1 = df.between,
df2 = df.within, lower.tail = F)
# Leave out the FFI+CF so the Group factor only has two levels (FFI vs. Control)
# to demonstrate the similarity between an one-way independent-measures ANOVA
# and an unpaired two-sample t-test ASSUMING AN EQUAL VARIANCE. See the Unit 5
# handout for detailed explanations.
sl.sim.sub = subset(sl.sim, Group != "FFI+CF")
# Run the ANOVA
sl.sim.sub.aov = aov(formula = rF3 ~ Group, data = sl.sim.sub)
# Show the stats
summary(sl.sim.sub.aov)
# Run the unpaired t-test assuming an equal variance; the same df and p-value
# can be found.
t.test(formula = rF3 ~ Group, data = sl.sim.sub, var.equal = T)
# In this comparison, the squared t-value is equal to the F-value.
1.3268 ^ 2
# For pairwise comparisons, Bonferroni correction, and the TukeyHSD test, see
# Unit 5 handout for detailed explanations.
# In the full ANOVA model, we can make three pairwise comparisons, so the default
# alpha level .05 should be divided by 3, which is equal to .0167
bonferroni.a = .05 / 3
# Make pairwise comparisons between every two levels in Group to test between-level
# differences. Only the FFI-Control comparison does not have a p-value lower than
# 0.167
t.test(sl.sim.fficf$rF3, sl.sim.control$rF3, var.equal = T)
t.test(sl.sim.ffi$rF3, sl.sim.control$rF3, var.equal = T)
t.test(sl.sim.fficf$rF3, sl.sim.ffi$rF3, var.equal = T)
# Apply the TukeyHSD test to the entire ANOVA model for pairwise comparisons.
# Again, only the FFI-Control comparison does not have an adjusted p-value
# lower than .05
TukeyHSD(sl.sim.aov)
# One-way repeated-measures ANOVA
# See Unit 5 handout for the explanation of the within-subject design version
# of Saito and Lyster's simulated data
sl.rep.sim = loadCourseCSV(2024, "5_ANOVA", "SaitoLysterRepSim.csv")
# Calculate the by-subject rF3 average. WARNING: In real life, you SHOULD NOT
# do this because by-item variance also provides important information in
# statistical tests. I do this only for this demo. Please refer to Appendix B
# of the Unit 5 handout to see how to incorporate both by-subject and by-item
# analysis in ANOVA.
sl.rep.avg = aggregate(rF3 ~ Subject + Condition, FUN = mean, data = sl.rep.sim)
# Run the independent-measures ANOVA just for comparison; this is NOT the most
# appropriate ANOVA for a study with a within-subject design.
sl.rep.ind.aov = aov(formula = rF3 ~ Condition, data = sl.rep.avg)
summary(sl.rep.ind.aov)
# Run the MORE APPROPRIATE repeated-measures ANOVA
# First, convert Subject into a factor so the subject ID numbers are treated as
# "unit labels" rather than numeric values.
sl.rep.avg$Subject = as.factor(sl.rep.avg$Subject)
# Build the ANOVA model; the Error() term means "Condition is a within-subject
# design factor, so partition out the between-subject variance across the three
# paired samples.
sl.aov.rep = aov(formula = rF3 ~ Condition + Error(Subject / Condition),
data = sl.rep.avg)
# Compare the two ANOVA outputs and see the similarities and the differences.
# See the Unit 5 handout for detailed explanations.
summary(sl.aov.rep)
# Calculate the stats in one-way repeated-measures ANOVA manually to validate
# the numbers seen in sl.aov.rep
# The global/grand mean of rF3
mean.rep.global = mean(sl.rep.avg$rF3)
# The total variance (Sum of Squares): The squared differences between
# every single data point and the global mean
ss.rep.total = sum((sl.rep.avg$rF3 - mean.rep.global) ^ 2)
ss.rep.total
# Get the three paired samples based on Condition
sl.rep.cl = subset(sl.rep.avg, Condition == "Control")
sl.rep.ffi = subset(sl.rep.avg, Condition == "FFI")
sl.rep.fficf = subset(sl.rep.avg, Condition == "FFI+CF")
# Get the size of each paired sample
sl.rep.cl.n = nrow(sl.rep.cl)
sl.rep.ffi.n = nrow(sl.rep.ffi)
sl.rep.fficf.n = nrow(sl.rep.fficf)
# Get the mean rF3 of each paired sample
sl.rep.cl.mean = mean(sl.rep.cl$rF3)
sl.rep.ffi.mean = mean(sl.rep.ffi$rF3)
sl.rep.fficf.mean = mean(sl.rep.fficf$rF3)
# Calculate the interesting variance (the between-sample SS); this part is the
# same as in a one-way independent-measures ANOVA
ss.rep.between = sl.rep.cl.n * (sl.rep.cl.mean - mean.rep.global) ^ 2 +
sl.rep.ffi.n * (sl.rep.ffi.mean - mean.rep.global) ^ 2 +
sl.rep.fficf.n * (sl.rep.fficf.mean - mean.rep.global) ^ 2
ss.rep.between
# Calculate the by-subject average rF3
sl.rep.subj.mean = aggregate(rF3 ~ Subject, FUN = mean, data = sl.rep.avg)
sl.rep.subj.mean
# Calculate the between-unit (between-subject) variance; the number of levels
# in the independent variable multiplies the sum of the squared differences
# between each by-subject mean and the global mean.
ss.between_unit = 3 * sum((sl.rep.subj.mean$rF3 - mean.rep.global) ^ 2)
ss.between_unit
# Subtracting ss-between-sample and ss-between-unit from ss-total to get
# ss-error (SSE).
ss.rep.total - ss.rep.between - ss.between_unit
# TukeyHSD() doesn't work for repeated-measures ANOVA models, so it is not
# possible to run Tukey's HSD test for post-hoc pairwise comparison.
TukeyHSD(sl.aov.rep)
# related to the sample data set.
chen.sample = loadCourseCSV(2024, "5_ANOVA", "Chen2020Sample.csv")
head(chen.sample)
tail(chen.sample[-(1:100),])
xtabs(~ Group + InitialTone, data = chen.sample[-(1:100),])
xtabs(~ Group + InitialTone, data = chen.sample[-(1:50),])
summary(aov(formula = Accept ~ Group + InitialTone + Group:InitialTone,
data = data = chen.sample[-(1:50),]))
summary(aov(formula = Accept ~ Group + InitialTone + Group:InitialTone,
data = chen.sample[-(1:50),]))
summary(aov(formula = Accept ~ InitialTone + Group + Group:InitialTone,
data = chen.sample[-(1:50),]))
pt(q = -1.581, df = 100)
pt(q = -1.581, df = 100) * 2
setwd("D:/OneDrive - NTHU/Academic Works/NTHU/Courses/Language and Statistics in R/GitHub/Statistics_in_R")
library(languageR)
# Copy the fixed predictor PlosivePresent to another variable Pl.Pr.Fac
durationsOnt$Pl.Pr.Fac = durationsOnt$PlosivePresent
# Use contr.sum() and specify the number of levels in the predictor (2) to
# replace the default dummy coding extracted by contrasts()
contrasts(durationsOnt$Pl.Pr.Fac) = contr.sum(2)
# Check the contrast matrix; the contrasts sum to 0 (i.e., 1 + -1)
contrasts(durationsOnt$Pl.Pr.Fac)
dur.lm.plo.sum = lm(formula = DurationPrefixNasal ~ Pl.Pr.Fac,
data = durationsOnt)
summary(dur.lm.plo.sum)
