facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5))
ggplot(mapping = aes(x = n, y = d)) +
facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5)) +
labs(title = "Figure 4. Binomial vs. normal distribution for different sample Ns",
x = "hits", y = "density") +
theme_bw()
norms.10 = data.frame(n = seq(0, 10, 500), d = dnorm(seq(0, 10, 500), 5, sqrt(5 * 0.5)), SampleN = "Sample N = 10")
norms.50 = data.frame(n = seq(0, 50, 2500), d = dnorm(seq(0, 50, 2500), 25, sqrt(25 * 0.5)), SampleN = "Sample N = 50")
ggplot(mapping = aes(x = n, y = d)) +
facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5)) +
labs(title = "Figure 4. Binomial vs. normal distribution for different sample Ns",
x = "hits", y = "density") +
theme_bw()
head(norms.10)
head(seq(0, 50, 2500))
?seq
norms.10 = data.frame(n = seq(0, 10, 500), d = dnorm(seq(0, 10, length = 500), 5, sqrt(5 * 0.5)), SampleN = "Sample N = 10")
norms.50 = data.frame(n = seq(0, 50, 2500), d = dnorm(seq(0, 50, length = 2500), 25, sqrt(25 * 0.5)), SampleN = "Sample N = 50")
head(norms.10)
ggplot(mapping = aes(x = n, y = d)) +
facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5)) +
labs(title = "Figure 4. Binomial vs. normal distribution for different sample Ns",
x = "hits", y = "density") +
theme_bw()
norms.10 = data.frame(n = seq(0, 10, length = 500), d = dnorm(seq(0, 10, length = 500), 5, sqrt(5 * 0.5)), SampleN = "Sample N = 10")
norms.50 = data.frame(n = seq(0, 50, length = 2500), d = dnorm(seq(0, 50, length = 2500), 25, sqrt(25 * 0.5)), SampleN = "Sample N = 50")
ggplot(mapping = aes(x = n, y = d)) +
facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5)) +
labs(title = "Figure 4. Binomial vs. normal distribution for different sample Ns",
x = "hits", y = "density") +
theme_bw()
ggplot(mapping = aes(x = n, y = d)) +
facet_grid(~ SampleN, scales = "free") +
geom_line(data = rbind(norms.10, norms.50), stat = "identity", lwd = 1, color = "grey40") +
geom_point(data = rbind(binoms.10, binoms.50), stat = "identity", size = 1.5, color = "red", alpha = 0.5) +
scale_x_continuous(breaks = seq(0, 50, 5)) +
labs(title = "Figure 4. Binomial vs. normal distribution for different sample Ns",
caption = "Grey curve = Normal Distribution",
x = "hits", y = "density") +
theme_bw()
# The URL for the resources of these three weeks
resourcesURL = "https://lngproc.fl.nthu.edu.tw/statisticsR/Week5-7/"
overgen = read.csv(paste(resourcesURL, "overgen.csv", sep = ""),
fileEncoding = "UTF-8-BOM")
)
paste(resourcesURL, "overgen.csv", sep = "")
overgen = read.csv(paste(resourcesURL, "overgen.csv", sep = ""),
fileEncoding = "UTF-8-BOM")
str(overgen)
head(overgen)
overgen = read.csv(paste(resourcesURL, "overgen.csv", sep = ""),
fileEncoding = "UTF-8-BOM")
str(overgen)
set.seed(1)
for(i in 1:10) {
rnorm(1)
}
set.seed(1)
for(i in 1:10) {
print(rnorm(1))
}
set.seed(1)
for(i in 1:10) {
print(rnorm(1))
}
set.seed(1)
print(rnorm(1))
print(rnorm(1))
set.seed(1)
print(rnorm(1))
print(rnorm(1))
mean.pop = 300
sd.pop = 40
mean.sample = 325
n = 10
# Calculate SE
se = 40 / sqrt(n)
# Get the CI range extended from the sample mean
ci.upper = mean.sample + 1.96 * se	#
ci.lower = mean.sample - 1.96 * se	#
ci.upper
ci.lower
?qt
qt(p = .025, df = 20)
qt(p = .025, df = 30)
library(verb)
library(langaugeR)
library(languageR)
?verb
?verbs
head(verbs)
?dative
head(dative)
library(languageR)
head(durationsOnt)
head(dative)
head(dativeSimplified)
head(verbs)
xtabs(~ RealizationOfRec + AnimacyOfRec, data = verbs)
xtabs(~ RealizationOfRec + AnimacyOfRec + AnimacyOfTheme, data = verbs)
xtabs(~ RealizationOfRec + AnimacyOfRec, data = verbs)
table(verbs$Verb)
xtabs(~ RealizationOfRec + AnimacyOfRec, data = subset(verbs, Verb == "sell" | Verb == "give"))
xtabs(~ RealizationOfRec + AnimacyOfRec, data = subset(verbs, Verb == "sell" | Verb == "give")) / nrow(subset(verbs, Verb == "sell" | Verb == "give"))
xtabs(~ RealizationOfRec + AnimacyOfRec, data = verbs) / nrow(verbs)
xtabs(RealizationOfRec ~ AnimacyOfRec, data = verbs) / nrow(verbs)
?xtabs
verbs.table = table(verbs$Verb)
order(verbs.table, decreasing = T)
sort(verbs.table, decreasing = T)
?round
source("https://lngproc.fl.nthu.edu.tw/statisticsR/courseUtil.R")
Myers.sample = loadCourseCSV("Week3-4", "Myers_2015_Sample.csv")
Myers.resp = subset(Myers.sample, RT > 0)
Myers.noShortRT = subset(Myers.resp, RT > 200)
plot(density(Myers.noShortRT$RT))
?barplot
?ifelse
source("https://lngproc.fl.nthu.edu.tw/statisticsR/courseUtil.R")
Myers.sample = loadCourseCSV("Week3-4", "Myers_2015_Sample.csv")
Myers.resp = subset(Myers.sample, RT > 0)
nrow(Myers.resp)
Myers.noShortRT = subset(Myers.resp, RT > 200)
nrow(Myers.resp) - nrow(Myers.noShortRT) 	# 2,120 rows were dropped
[1] 2120
qqnorm(Myers.noShortRT$RT, main = "Normal Q-Q Plot (RT in Myers, 2015)")
qqline(Myers.noShortRT$RT, lwd = 2, col = "red")
But according to Brysbaert & Stevens (2018), a transformation using -1000 / RT in milliseconds (or inverse RT) is even better. Letâ€™s do both and make a comparison.
Myers.noShortRT$logRT = log(Myers.noShortRT$RT)	# Standard Treatment
# Brysbaert & Stevens (2018)
Myers.noShortRT$inverseRT = -1000 / Myers.noShortRT$RT
# Compare the two new RT distribution
par(mfrow = c(1, 2))	# Set a panel with one row and two columns
qqnorm(Myers.noShortRT$logRT, main = "Normal Q-Q Plot (log-RT in Myers, 2015)")
qqline(Myers.noShortRT$logRT, lwd = 2, col = "red")
qqnorm(Myers.noShortRT$inverseRT,
main = "Normal Q-Q Plot (inverse-RT in Myers, 2015)")
qqline(Myers.noShortRT$inverseRT, lwd = 2, col = "red")
par(mfrow = c(1, 1))	# Reset the panel
head(Myers.noShortRT$inverseRT)
norm.dist = rnorm(1000, 0, 40)
sd(norm.dist)
sd(norm.dist) ^ 2
var(norm.dist)
var(norm.dist) / 999 - 0
norm.dist ^ 2 / 999
sum(norm.dist ^ 2 / 999)
source("https://lngproc.fl.nthu.edu.tw/statisticsR/courseUtil.R")
jabberwocky.wd = loadCourseCSV("Week3-4", "jabberwocky_words.txt")
jabberwocky.table = table(jabberwocky.wd$Word)
# To show the data type of jabberwocky.table
is(jabberwocky.table)
[1] "table"    "oldClass"
# Check the content
head(jabberwocky.table)
jabberwocky.df = as.data.frame(jabberwocky.table)
colnames(jabberwocky.df) = c("Word", "Count")
count.des.ord = order(jabberwocky.df$Count, decreasing = T)
# Save the reordered data frame to jabberwocky.ord
jabberwocky.ord = jabberwocky.df[count.des.ord,]
jabberwocky.wordCat = loadCourseCSV("Week3-4", "jabberwocky_words_cat.csv")
pos.na = is.na(jabberwocky.wordCat$POS)
head(pos.na)
jabberwocky.all = merge(jabberwocky.ord, jabberwocky.wordCat, by = "Word")
xtabs(formula = ~ Count + Real, data = jabberwocky.all)
Myers.sample = loadCourseCSV("Week3-4", "Myers_2015_Sample.csv")
Myers.noResp = subset(Myers.sample, RT == 0)
Myers.resp = subset(Myers.sample, RT > 0)
Myers.noShortRT = subset(Myers.resp, RT > 200)
qqnorm(Myers.noShortRT$RT, main = "Normal Q-Q Plot (RT in Myers, 2015)")
qqline(Myers.noShortRT$RT, lwd = 2, col = "red")
Myers.logRT.mean = mean(Myers.noShortRT$logRT)	# 6.98454
Myers.logRT.sd = sd(Myers.noShortRT$logRT)		# 0.6266754
# We also use subset() here again, but now we have two conditions joined
# by the logical operator "&", which means AND. Thus, the outcome is TRUE if
# and only if both conditions are TRUE.
Myers.sd25 = subset(Myers.noShortRT,
logRT >= Myers.logRT.mean - Myers.logRT.sd * 2.5 &
logRT <= Myers.logRT.mean + Myers.logRT.sd * 2.5)
Myers.noShortRT$logRT = log(Myers.noShortRT$RT)	# Standard Treatment
# Brysbaert & Stevens (2018)
Myers.noShortRT$inverseRT = -1000 / Myers.noShortRT$RT
# Get the mean and the sd of inverse RT
Myers.logRT.mean = mean(Myers.noShortRT$logRT)	# 6.98454
Myers.logRT.sd = sd(Myers.noShortRT$logRT)		# 0.6266754
# We also use subset() here again, but now we have two conditions joined
# by the logical operator "&", which means AND. Thus, the outcome is TRUE if
# and only if both conditions are TRUE.
Myers.sd25 = subset(Myers.noShortRT,
logRT >= Myers.logRT.mean - Myers.logRT.sd * 2.5 &
logRT <= Myers.logRT.mean + Myers.logRT.sd * 2.5)
# 226 rows were excluded in the above screening process; 13952 rows left
nrow(Myers.noShortRT) - nrow(Myers.sd25)
cor(Myers.sd25$Session, Myers.sd25$RT)
cor(Myers.sd25$Session, Myers.sd25$Response)
aggregate(Response ~ Session + Participant, FUN = mean, data = Myers.sd25)
library(languageR)
?auxiliaries
head(auxiliaries)
max(auxiliaries$VerbalSynsets)
min(auxiliaries$VerbalSynsets)
median(auxiliaries$VerbalSynsets)
auxiliaries$moreSyn = ifelse(auxiliaries$VerbalSynsets > median(auxiliaries$VerbalSynsets), "Yes", "No")
head(auxiliaries)
xtabs(Verbs ~ Aux + moreSyn, data = auxiliaries)
xtabs(Verb ~ Aux + moreSyn, data = auxiliaries)
xtabs(~ Verbs + Aux + moreSyn, data = auxiliaries)
xtabs(~ Verb + Aux + moreSyn, data = auxiliaries)
xtabs(Aux ~ Regularity + moreSyn, data = auxiliaries)
xtabs(~ Aux + Regularity + moreSyn, data = auxiliaries)
head(oldFrench)
head(english)
nrow(english)
?english
qqnorm(english$NounFrequency)
qqnorm(english[english$WordCategory == "N",]$NounFrequency)
nrow(subset(english, WordCategory == "N"))
cor(english$RTlexdec, english$RTnaming)
library(languageR)
head(verbs)
xtabs(~ RealizationOfRec + AnimacyOfTheme, data = verbs)
xtabs(~ RealizationOfRec + AnimacyOfRec, data = verbs)
sum(verbs$Count)
sum(xtabs(~ RealizationOfRec + AnimacyOfRec, data = verbs))
nrow(verbs)
qnorm(0.01)
qnorm(0.05)
qnorm(0.025)
qnorm(0.005)
sd(c(5, 10))
sd(c(50, 100))
50 / 35.35534
5 / 3.535534
10 / 3.535534
100 / 35.35534
mean.pop = 300
sd.pop = 40
mean.sample = 320
n = 10
# Calculate SE
se = 40 / sqrt(n)
# Get the CI range extended from the sample mean
ci.upper = mean.sample + 1.96 * se	# 349.7923
ci.lower = mean.sample - 1.96 * se
ci.lower
ci.upper
contr.helmert(3)
contr.helmert(2)
contr.contr(2)
contr.sum(2)
contr.treatment(2)
library(languageR)
english.sub = subset(english, WordCategory == "N")
# 2,904 words
english.sub = english.sub[c("RTlexdec", "NounFrequency", "Familiarity",
"Word")]
english.sub$NounFreq.log = log(english.sub$NounFrequency + 1)
durationsOnt$Sex.Fac = as.factor(durationsOnt$Sex)
durationsOnt$Pl.Pr.Fac = as.factor(durationsOnt$PlosivePresent)
# Use contr.sum() to create a sum-coding contrasts for two levels
contrasts(durationsOnt$Sex.Fac) = contr.sum(2)
contrasts(durationsOnt$Pl.Pr.Fac) = contr.sum(2)
colnames(contrasts(durationsOnt$Sex.Fac)) = levels(durationsOnt$Sex.Fac)[2]
colnames(contrasts(durationsOnt$Pl.Pr.Fac)) =
levels(durationsOnt$Pl.Pr.Fac)[2]
dur.lm.sum = lm(DurationPrefixNasal ~ Pl.Pr.Fac * Sex.Fac,
data = durationsOnt)
dur.lm.sum$contrasts
summary(dur.lm.sum)
0.055825 + 1 * 0.012743 + 1 * -0.001012 + 1 * 1 * -0.003859
0.055825 + 1 * 0.012743 + -1 * -0.001012 + 1 * -1 * -0.003859
0.055825 + -1 * 0.012743 + 0 * -0.001012 + -1 * 0 * -0.003859
0.055825 + -1 * 0.012743 + -1 * -0.001012 + -1 * -1 * -0.003859
0.055825 + 1 * 0.012743 + -1 * -0.001012 + 1 * -1 * -0.003859
0.055825 + -1 * 0.012743 + 1 * -0.001012 + -1 * 1 * -0.003859
0.055825 + 1 * 0.012743 + 1 * -0.001012 + 1 * 1 * -0.003859
library(languageR)
headA(english)
head(english)
?var.test
english.var = var.test(x = english.old$RTnaming, y = english.young$RTnaming)
english.old = subset(english, AgeSubject == "old")
english.young = subset(english, AgeSubject == "young")
# Run the test of variance in RTnaming
rt.naming.var = var.test(x = english.old$RTnaming, y = english.young$RTnaming)
rt.naming.var$p.value
t.test(x = english.old$RTnaming, y = english.young$RTnaming, var = FALSE)
t.test(x = english.old$RTnaming, y = english.young$RTnaming, var = TRUE)
log(1)
setwd("D:/OneDrive/Documents/Academic Works/NTHU/Courses/Language and Statistics in R/GitHub/Statistics_in_R/Week11-14")
library(ggplot2)
rbinom(n = 5, size = 10, prob = .5)
rbinom(n = 5, size = 2, prob = .5)
rbinom(n = 5, size = 1, prob = .5)
logOdds = 0
for(i in 1:100000) {
x = rbinom(n = 10000, size = 1, prob = .5)
n.1 = length(x[x==1])
p = n.1 / 10000
logOdds[i] = log(p / (1 - p))
}
ggplot() + geom_density(data = logOdds)
ggplot() + geom_density(data = as.data.frame(logOdds))
logOdds.df = data.frame(x = logOdds)
ggplot() + geom_density(data = logOdds, x = x)
ggplot() + geom_density(data = logOdds.df, x = x)
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x))
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
labs(x = "Logit", y = "Density", title = "Figure 8. Logit Distribution") +
theme_bw()
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
scale_x_binned(n.breaks = 5) +
labs(x = "Logit", y = "Density", title = "Figure 8. Logit Distribution") +
theme_bw()
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
scale_x_binned(n.breaks = 10) +
labs(x = "Logit", y = "Density", title = "Figure 8. Logit Distribution") +
theme_bw()
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
labs(x = "Logit", y = "Density", title = "Figure 8. Logit Distribution") +
theme_bw()
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
scale_x_continuous(limits = c(-0.075, 0.075)) +
labs(x = "Logit", y = "Density", title = "Figure 8. Logit Distribution") +
theme_bw()
ggplot() + geom_density(data = logOdds.df, mapping = aes(x = x), lwd = 2) +
scale_x_continuous(limits = c(-0.075, 0.075)) +
labs(x = "Logit", y = "Density", title = "Figure 9. Logit Distribution") +
theme_bw()
odds = seq(0, 1, by = .01)
head(odds)
odds = seq(0.001, 0.999, by = .01)
logistic.df = data.frame(Odds = odds, Logits = log(odds))
ggplot(data = logistic.df, mapping = aes(x = Odds, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Odds-ratio", y = "Logits") +
theme_bw()
log(1)
odds = seq(0.001, 1.999, by = .01)
logistic.df = data.frame(Odds = odds, Logits = log(odds))
ggplot(data = logistic.df, mapping = aes(x = Odds, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Odds-ratio", y = "Logits") +
theme_bw()
odds = seq(0.001, 5.999, by = .01)
logistic.df = data.frame(Odds = odds, Logits = log(odds))
ggplot(data = logistic.df, mapping = aes(x = Odds, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Odds-ratio", y = "Logits") +
theme_bw()
exp(6)
odds = seq(0.001, 400, by = .01)
logistic.df = data.frame(Odds = odds, Logits = log(odds))
ggplot(data = logistic.df, mapping = aes(x = Odds, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Odds-ratio", y = "Logits") +
theme_bw()
prob = seq(0.01, 1, by = .01)
logistic.df = data.frame(Prob = prob, Logits = log(prob / (1 - rpbo)))
ggplot(data = logistic.df, mapping = aes(x = Prob, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Probability", y = "Logits") +
theme_bw()
prob = seq(0.01, 1, by = .01)
logistic.df = data.frame(Prob = prob, Logits = log(prob / (1 - prob)))
ggplot(data = logistic.df, mapping = aes(x = Prob, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Probability", y = "Logits") +
theme_bw()
prob = seq(0.01, 0.99, by = .01)
logistic.df = data.frame(Prob = prob, Logits = log(prob / (1 - prob)))
ggplot(data = logistic.df, mapping = aes(x = Prob, y = Logits)) +
geom_line(lwd = 2) +
labs(title = "Figure 8. Logistic Function", x = "Probability", y = "Logits") +
theme_bw()
source("https://lngproc.fl.nthu.edu.tw/statisticsR/courseUtil.R")
chen.sample = loadCourseCSV("Week10-11", "Chen2020Sample.csv")
head(chen.sample)
chen.sample$InitialTone_Fac = as.factor(chen.sample$InitialTone)
chen.sample$Group_Fac = as.factor(chen.sample$Group)
# Convert dummy coding into sum coding with contr.sum()
contrasts(chen.sample$InitialTone_Fac) = contr.sum(2)
colnames(chen.sample$InitialTone_Fac) =
levels(chen.sample$InitialTone_Fac)[2]
contrasts(chen.sample$Group_Fac) = contr.sum(2)
colnames(chen.sample$Group_Fac) = levels(chen.sample$Group_Fac)[2]
colnames(chen.sample$InitialTone_Fac)
contrasts(chen.sample$InitialTone_Fac) = contr.sum(2)
colnames(contrasts(chen.sample$InitialTone_Fac)) =
levels(chen.sample$InitialTone_Fac)[2]
contrasts(chen.sample$Group_Fac) = contr.sum(2)
colnames(contrasts(chen.sample$Group_Fac)) = levels(chen.sample$Group_Fac)[2]
contrasts(chen.sample$Group_Fac)
chen.glm = glm(Accept ~ InitialTone_Fac * Group_Fac, family = "binomial",
data = chen.sample)
summary(chen.glm)
exp(0.04788)
1.049095 / (1 + 1.049095)
chen.ef = as.data.frame(effect("InitialTone_Fac:Group_Fac", chen.glm))
library(effects)
chen.ef = as.data.frame(effect("InitialTone_Fac:Group_Fac", chen.glm))
hea(chen.ef)
head(chen.ef)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, color = Group_Fac)) +
geom_line() + geom_errorbar(mapping = aes(upper = upper, lower = lower))
?geom_errorbar
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, color = Group_Fac)) +
geom_line(lwd = 1.5) + geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group") + theme_bw()
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group") + theme_bw()
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group") + theme_bw()
chen.ef
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity") +
#geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group") + theme_bw()
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac))
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 2)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1)
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1)
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1)
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1)
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability") +
guides(color = "Group")
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability", color = "Group") + theme_bw()
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
y = "Fitted Probability of Acceptance", color = "Group") + theme_bw()
ggplot(data = chen.ef, mapping = aes(x = InitialTone_Fac, y = fit, group = Group_Fac, color = Group_Fac)) +
geom_line(stat = "identity", lwd = 1.5) + geom_point(stat = "identity", size = 4) +
geom_errorbar(mapping = aes(ymax = upper, ymin = lower), lwd = 1.5, width = .1) +
labs(title = "Figure 10. Logistic Regression for Chen (2020) Sample",
subtitle = "Accept ~ Initial Tone x Group", x = "Initial Tone",
caption = "Error bars = SE",
y = "Fitted Probability of Acceptance", color = "Group") + theme_bw()
