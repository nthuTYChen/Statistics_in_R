lexdec.mean = mean(lexdec$RT)
lexdec.sd = sd(lexdec$RT)
lexdec.sub = subset(lexdec.sd2, Correct == "correct")
library(languageR)
head(lexdec)
#Task I
lexdec.mean = mean(lexdec$RT)
lexdec.sd = sd(lexdec$RT)
lexdec.sub = subset(lexdec.sd2, Correct == "correct")
75*0.4*2
75*0.04*2
50*0.3
10*0.04
75*0.04
17.6 / 0.3
75*0.04*3
8.6 - 6
library(languageR)
head(lexdec)
# Part I
# Task I – Exclude outliers in RT and Frequency with the boundaries set to mean ± 2SD using subset(),
# and store the output as lexdec.sub.
rt.upper = mean(lexdec$RT) + 2 * sd(lexdec$RT)
rt.lower = mean(lexdec$RT) - 2 * sd(lexdec$RT)
frequency.upper = mean(lexdec$Frequency) + 2 * sd(lexdec$Frequency)
frequency.lower = mean(lexdec$Frequency) - 2 * sd(lexdec$Frequency)
lexdec.sub = subset(lexdec, RT <= rt.upper & RT >= rt.lower &
Frequency <= frequency.upper & Frequency >= frequency.lower)
plot(density(lexdec.sub$RT), main = "The distribution of log-transformed lexical decision times")
plot(density(lexdec.sub$Frequency), main = "The distribution of log-transformed word frequencies")
plot(RT ~ Frequency, data = lexdec.sub,
main = "RT - Frequency Correlation in lexdec.sub",
xlab = "log-transformed word frequencies",
ylab = "log-transformed lexical decision times")
lexdec.lm = lm(formula = RT ~ Frequency, data = lexdec.sub)
summary(lexdec.lm)
exp(6.523106 + 4.3 * -0.035142)
exp(6.523106 + 5 * -0.035142)
exp(6.523106 + 7.2 * -0.035142)
# Task VI – Fit a new linear regression model to the dataset lexdec.sub, in which the dependent variable RT is regressed
# against two independent variables Frequency and FamilySize. Store the model as lexdec.lm2, and show the output with summary().
# In comment lines, report the two main effects following the APA format, and explain how much more variance is explained in
# lexdec.lm2 compared to lexdec.lm (focus on r2).
lexdec.lm2 = lm(formula = RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
lexdec.lm3 = lm(formula = RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
# (a)
exp(6.492405 + 3.5 * -0.026865 + 1.3 * 0.021836 + 3.5 * 1.3 * -0.006208)
# (b)
exp(6.492405 + 2.8 * -0.026865 + 2.4 * 0.021836 + 2.8 * 2.4 * -0.006208)
library(ggplot2)
ggplot(data = lexdec.sub, aes(x = Frequency, y = RT)) +
geom_point(color = "grey40", size = 3, alpha = 0.7) +
geom_smooth(method = "lm", se = F, color = "red", lwd = 1.5) +
labs(title = "Correlation between Frequency and RT",
subtitle = "Linear regression: RT ~ Frequency",
x = "log-transformed Word Frequency", y = "log-transformed Lexical Decision RT") + theme_bw()
freq.fam.val = data.frame(Frequency = seq(from = 2, to = 3, by = 0.1), FamilySize = seq(from = 0.5, to = 1.5, by = 0.1))
RT.pred = predict(object = lexdec.lm3, newdata = freq.fam.val)
RT.pred
library(languageR)
head(lexdec)
#Part I
#1
lexdec.sub = subset(
lexdec, RT > mean(RT) - 2 * sd(RT) & RT < mean(RT) + 2 * sd(RT) & Frequency > mean(Frequency) - 2 * sd(Frequency) & Frequency < mean(Frequency) + 2 * sd(Frequency)
)
#2
#a.
plot(density(lexdec.sub$RT), main = "Log-transformed Reaction Times Distribution Graph")
plot(density(lexdec.sub$Frequency), main = "Log-transformed Word Frequency Distribution Graph")
#b.
plot(lexdec.sub$Frequency, y = lexdec.sub$RT, main = "Reaction Times ~ Word Frequency", xlab = "log Reaction Times", ylab = "log Word Frequency")
#Linearity and homoscedasticity are violated.
#3
lexdec.lm = lm(formula = RT ~ Frequency, data = lexdec.sub)
summary(lexdec.lm)
#5
#Frequency = 4.3
exp(6.523106 + 4.3 * (-0.035142))
#Frequency = 5
exp(6.523106 + 5 * (-0.035142))
#Frequency = 7.2
exp(6.523106 + 7.2 * (-0.035142))
#Part II
#6
lexdec.lm2 = lm(formula = RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
#7
lexdec.lm3 = lm(formula = RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
#8
#a.
exp(6.492405 + 3.5 * (-0.026865) + 1.3 * 0.021836 + 3.5 * 1.3 * (-0.006208))
#b.
exp(6.492405 + 2.8 * (-0.026865) + 2.4 * 0.021836 + 2.8 * 2.4 * (-0.006208))
#Bonus
#9
library(ggplot2)
ggplot(lexdec.sub, aes(x = Frequency, y = RT)) + geom_point(alpha = 0.7, color = "gray40") + geom_smooth(method = "lm", se = F, color = "red", lwd = 1.5) +
labs(title = "Reaction Times ~ Word Frequency", subtitle = "r = -0.2009, t(1498) = –7.937, p < .005", x = "log Word Frequency", y = "log Reaction Times")
#10
freq_df = data.frame(Frequency = seq(from = 2, to = 3, by = 0.1))
fs_df = data.frame(FamilySize = seq(from = 0.5, to = 1.5, by = 0.1))
intervals = merge(freq_df, fs_df)
RT_pred = predict(object = lexdec.lm3, newdata = intervals)
RT_pred
head(intervals)
library(languageR)
head(lexdec)
# Part I
# Task I – Exclude outliers in RT and Frequency with the boundaries set to mean ± 2SD using subset(),
# and store the output as lexdec.sub.
rt.upper = mean(lexdec$RT) + 2 * sd(lexdec$RT)
rt.lower = mean(lexdec$RT) - 2 * sd(lexdec$RT)
frequency.upper = mean(lexdec$Frequency) + 2 * sd(lexdec$Frequency)
frequency.lower = mean(lexdec$Frequency) - 2 * sd(lexdec$Frequency)
lexdec.sub = subset(lexdec, RT <= rt.upper & RT >= rt.lower &
Frequency <= frequency.upper & Frequency >= frequency.lower)
# Task II – (a) Are both RT and Frequency normally distributed? Generate a density plot for each variable
# with an informative title and answer the question in comment lines.
plot(density(lexdec.sub$RT), main = "The distribution of log-transformed lexical decision times")
plot(density(lexdec.sub$Frequency), main = "The distribution of log-transformed word frequencies")
# Yes, I think they both are close enough to a normal distribution.
# Task II – (b) Are linearity and homoscedasticity violated? Generate a scatter plot with informative titles
# and axis labels and answer the question in comment lines.
plot(RT ~ Frequency, data = lexdec.sub,
main = "RT - Frequency Correlation in lexdec.sub",
xlab = "log-transformed word frequencies",
ylab = "log-transformed lexical decision times")
# Yes, linearity and homoscedasticity are violated since we see that (i) the correlation is not linear, and
# (ii) the variation across the x-axis is not similar.
# Task III – Fit a linear regression model to the data in lexdec.sub using lm(). Store the modeling results
# as lexdec.lm and use summary() to show the critical information from the model, and report the main effect
# of Frequency following the APA format in comment lines.
lexdec.lm = lm(formula = RT ~ Frequency, data = lexdec.sub)
summary(lexdec.lm)
# We tested our hypothesis with a linear regression model in which log-transformed lexical decision RT was regressed against
# log-transformed word frequency and found the main effect of word frequency to be significant (B = -0.035, SE = 0.004,
# t(1498) = -7.94, p < .001) with a small effect size (r-squared = 0.04035).
# Task IV – Explain in comment lines what the number of the beta coefficient of Frequency means and whether it supports
# our hypothesis regarding the effect of word frequency on lexical decision RT.
# The number of the beta coefficient of Frequency means that when "Frequency" increases by 1, the lexical decision time
# "RT" decreases by 0.035s. Together with the fact that this negative effect is significant, our hypothesis – the more
# frequent a word is, the faster it is retrieved and judged – is supported.
# Task V – Manually calculate the predicted RT when Frequency is 4.3, 5, and 7.2 respectively with the statistics from
# the linear regression model in lexdec.lm lm. Convert the predicted RTs into raw RTs using exp().
exp(6.523106 + 4.3 * -0.035142)
exp(6.523106 + 5 * -0.035142)
exp(6.523106 + 7.2 * -0.035142)
# Part II
# Task VI – Fit a new linear regression model to the dataset lexdec.sub, in which the dependent variable RT is regressed
# against two independent variables Frequency and FamilySize. Store the model as lexdec.lm2, and show the output with summary().
# In comment lines, report the two main effects following the APA format, and explain how much more variance is explained in
# lexdec.lm2 compared to lexdec.lm (focus on r2).
lexdec.lm2 = lm(formula = RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
# We fitted a linear regression model to log-transformed lexical decision RT, in which log-transformed word frequency and
# word family size were included as independent variables. Our analysis suggests the main negative effect of word frequency
# to be significant (B = -0.029, SE = 0.006, t(1497) = -4.98, p < .001), and the main negative effect of word family size
# to be nonsignificant (B = -0.013, SE = 0.008, t(1497) = -1.58, p = 0.11).
# We can see that in lexdec.lm, the r-squared value is 0.04035, and in lexdec.lm2 the r-squared value is 0.04195.
# Therefore, comparing to lexdec.lm, the increase in the explained variance in lexdec.lm2 is 0.16%.
# Task VII – Fit another new linear regression model to the dataset lexdec.sub, in which the dependent variable RT is regressed
# against two independent variables Frequency and FamilySize as well as their two-way interaction. Store the model as lexdec.lm3,
# and show the output with summary(). In comment lines, report the two main effects following the APA format, and explain how much
# more variance is explained in lexdec.lm3 compared to lexdec.lm2. In addition, explain the number represented by the interaction
# coefficient and explain if the main effect of Frequency significantly varies by FamilySize.
lexdec.lm3 = lm(formula = RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
# We fitted a linear regression model to log-transformed lexical decision RT, in which log-transformed word frequency and
# word family size were included as independent variables, and their interaction was also taken into consideration. Our
# analysis suggests the main negative effect of word frequency to be significant (B = -0.027, SE = 0.006, t(1496) = -4.26, p < .001),
# and the main positive effect of word family size to be nonsignificant (B = 0.022, SE = 0.038, t(1496) = 0.58, p = 0.56).
# The two-way interaction is also nonsignificant (B = -0.006, SE =0.007 , t(1496) = -0.96, p = 0.34).
# We can see that in lexdec.lm2, the r-squared value is 0.04195, and in lexdec.lm3 the r-squared value is 0.04253.
# Therefore, comparing to lexdec.lm2, the increase in the explained variance in lexdec.lm3 is 0.058%.
# The number represented by the interaction coefficient is -0.006208, and this number suggests that the negative effect of word frequency
# is stronger (-0.006208) when the target word has a larger family size. That is, when the family size increases by 1, the negative effect
# of word frequency would increase by 0.006208. However, our analysis suggests that this interaction is not significant, which in turn means
# that the main effect of Frequency would not significantly vary by FamilySize.
# Task VIII – Manually calculate the predicted RT in two cases based on the statistics in lexdec.lm3: (a) Frequency = 3.5 and FamilySize = 1.3,
# and (b) Frequency = 2.8 and FamilySize = 2.4. Convert the predicted RTs into raw RTs using exp().
# (a)
exp(6.492405 + 3.5 * -0.026865 + 1.3 * 0.021836 + 3.5 * 1.3 * -0.006208)
# (b)
exp(6.492405 + 2.8 * -0.026865 + 2.4 * 0.021836 + 2.8 * 2.4 * -0.006208)
# Bonus
# Task IX – Use ggplot2 to generate a scatterplot to show how RT varies by Frequency in lexdec.sub and add a trendline that represents the main effect
# of Frequency from a simple linear regression modeling.
library(ggplot2)
ggplot(data = lexdec.sub, aes(x = Frequency, y = RT)) +
geom_point(color = "grey40", size = 3, alpha = 0.7) +
geom_smooth(method = "lm", se = F, color = "red", lwd = 1.5) +
labs(title = "Correlation between Frequency and RT",
subtitle = "Linear regression: RT ~ Frequency",
x = "log-transformed Word Frequency", y = "log-transformed Lexical Decision RT") + theme_bw()
# Task X – Use the predict() function to generate predicted RTs with the model lexdec.lm3. The values in the two independent variables should range from 2 to 3
# for Frequency and from 0.5 to 1.5 for FamilySize, and the values in each variable should be separated by an interval of 0.1. Both variables should be included
# in the same data frame to be submitted to the predict() function.
freq.fam.val = data.frame(Frequency = seq(from = 2, to = 3, by = 0.1), FamilySize = seq(from = 0.5, to = 1.5, by = 0.1))
RT.pred = predict(object = lexdec.lm3, newdata = freq.fam.val)
RT.pred
library(languageR)
head(lexdec)
# Part I
# Q1
sd.lower.rt <- mean(lexdec$RT) - sd(lexdec$RT) * 2
sd.upper.rt <- mean(lexdec$RT) + sd(lexdec$RT) * 2
sd.lower.freq <- mean(lexdec$Frequency) - sd(lexdec$Frequency) * 2
sd.upper.freq <- mean(lexdec$Frequency) + sd(lexdec$Frequency) * 2
lexdec.sub <- subset(lexdec, RT < sd.upper.rt & RT > sd.lower.rt & Frequency < sd.upper.freq & Frequency > sd.lower.freq)
# Q2
# (a)
plot(density(lexdec.sub$RT), main = "Log-transformed Reaction Time of Lexical Decision (Density)")
abline(v = mean(lexdec.sub$RT), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$RT), col = "blue", lwd = 1.5)
plot(density(lexdec.sub$Frequency), main = "Log-transformed Frequency of Lexical Decision (Density)")
abline(v = mean(lexdec.sub$Frequency), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$Frequency), col = "blue", lwd = 1.5)
# (b)
library(ggplot2)
ggplot(data = lexdec.sub, aes(x = Frequency, y = RT)) +
geom_point(color = "grey20", size = 2, alpha = 0.5) +
geom_smooth(method = "lm", se = F, color = "red") +
labs(title = "Correlation between Reaction Time and Word Frequency in Lexical Decision",
x = "log-transformed Frequency", y = "log-transformed Reaction Time") + theme_bw()
# When Frequency increases, RT decreases. So linearity is not violated.
# However, while some values are near the regression line, others are much more distant from the regression line.
# So homoscedasticity is violated here.
# Q3
lexdec.lm <- lm(RT ~ Frequency, lexdec.sub)
summary(lexdec.lm)
# Q5
# (4.3)
exp(6.523106 + (-0.035142) * 4.3)
# (5)
exp(6.523106 + (-0.035142) * 5)
# (7.2)
exp(6.523106 + (-0.035142) * 7.2)
# Q6
lexdec.lm2 = lm(RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
# Q7
lexdec.lm3 <- lm(RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
# Q8
# (a)
exp(6.492405 + (-0.026865) * 3.5 + (0.021836) * 1.3 + 3.5 * 1.3 * (-0.006208))
# (b)
exp(6.492405 + (-0.026865) * 2.8 + (0.021836) * 2.4 + 2.8 * 2.4 * (-0.006208))
# Q9
ggplot(data = lexdec.sub, aes(x = Frequency, y = RT)) +
geom_point(color = "grey20", size = 2, alpha = 0.5) +
geom_smooth(method = "lm", se = F, color = "red") +
labs(title = "Correlation between RT and Word Frequency",
x = "log-transformed Frequency", y = "log-transformed Reaction Time") + theme_bw()
# Q10
values <- data.frame(Frequency = seq(from = 2, to = 3, by = 0.1), FamilySize = seq(from = 0.5, to = 1.5, by = 0.1))
exp(predict(object = lexdec.lm3, newdata = values))
library(languageR)
head(lexdec)
#Task I
mean_RT = mean(lexdec$RT)
sd_RT = sd(lexdec$RT)
mean_Frequency = mean(lexdec$Frequency)
sd_Frequency = sd(lexdec$Frequency)
lexdec.sub = subset(lexdec, RT > mean_RT - 2 * sd_RT &
RT < mean_RT + 2 * sd_RT &
Frequency > mean_Frequency - 2 * sd_Frequency &
Frequency < mean_Frequency + 2 * sd_Frequency)
#Task II
#RT
plot(density(lexdec.sub$RT), main = "Distribution of RT")
abline(v = mean(lexdec.sub$RT), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$RT), col = "blue", lwd = 1.5)
plot(density(lexdec.sub$Frequency), main = "Distribution of Frequency")
abline(v = mean(lexdec.sub$Frequency), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$Frequency), col = "blue", lwd = 1.5)
plot(lexdec.sub$RT, lexdec.sub$Frequency,
main = "Correlation between reaction time and Frequency in lexical decision task",
xlab = "reaction time",
ylab = "Frequency"  )
library(ggplot2)
ggplot(lexdec.sub, aes(x = Frequency, y = RT)) +
geom_point() +
labs(title = "Correlation between reaction time and Frequency in lexical decision task",
x = "RT",
y = "Frequency")
#Task III
lexdec.lm = lm(RT ~ Frequency, lexdec.sub)
summary(lexdec.lm)
#when Frequency is 4.3
rawRT_4.3 = exp(6.52 + (-0.035) * 4.3) #583.7659
#when Frequency is 5
rawRT_5 = exp(6.52 + (-0.035) * 5) #569.6374
#Task VI
lexdec.lm2 = lm(RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
#Task VII
lexdec.lm3 = lm(RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
#Task VIII
# (a)when Frequency is 3.5 and FamilySize = 1.3
exp(6.492 + (-0.027) * 3.5 + (0.022)*1.3 + 3.5*1.3*(-0.006))
#601.1233
# (b)when Frequency is 2.8  and FamilySize = 2.4.
exp(6.492 + (-0.027) * 2.8 + (0.022)*2.4 + 2.8*2.4*(-0.006))
#619.4797
#Task IX
library(ggplot2)
ggplot(data = lexdec.sub,
mapping = aes(x = Frequency, y = RT)) +
geom_point(color = "grey40", size = 3, alpha = 0.8) +
geom_smooth(method = "lm", se = F, color = "red", lwd = 1.5) +
labs(title = "Correlation between Reaction Time and Frequency in lexical decision task",
caption = "data are log-transformed",
x = "Frequency", y = "Reaction Time") + theme_bw()
library(languageR)
library(ggplot2)
#Task 1
lexdec.sub = subset(lexdec, RT < mean(lexdec$RT) + sd(lexdec$RT) * 2 &
RT > mean(lexdec$RT) - sd(lexdec$RT) * 2 &
Frequency < mean(lexdec$Frequency) + sd(lexdec$Frequency) * 2 &
Frequency > mean(lexdec$Frequency) - sd(lexdec$Frequency) * 2)
#Task 2
#RT
plot(density(lexdec.sub$RT), main = "Distribution of Reaction Time (log-transformed)")
abline(v = mean(lexdec.sub$RT), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$RT), col = "blue", lwd = 1.5)
#Frequency
plot(density(lexdec.sub$Frequency), main = "Distribution of Frequency (log-transformed)")
abline(v = mean(lexdec.sub$Frequency), col = "red", lwd = 1.5)
abline(v = median(lexdec.sub$Frequency), col = "blue", lwd = 1.5)
ggplot(data = lexdec.sub,
mapping = aes(x = Frequency, y = RT)) +
geom_point(color = "grey40", size = 3, alpha = 0.7) +
labs(title = "Correlation between Reaction Time and Frequency",
caption = "Frequency and Reaction time are log-transformed",
x = "Frequency", y = "Reaction Time") + theme_bw()
#As x (Freguency) changes, y (reactiom time) decreases but has a different scatter
#Accordingly, linearity is not violated, while homoscedasticity is.
lexdec.lm = lm(RT ~ Frequency, lexdec.sub)
summary(lexdec.lm)
#Task 5
#4.3
exp(6.523106 + (-0.035142) * 4.3)
#5
exp(6.523106 + (-0.035142) * 5)
#7.2
exp(6.523106 + (-0.035142) * 7.2)
#Task 6
lexdec.lm2 = lm(RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
#Task 7
lexdec.lm3 = lm(RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
#Task 8
# (a) 3.5 / 1.3
exp(6.492405 + (-0.026865) * 3.5 + (0.021836) * 1.3 + 3.5 * 1.3 * (-0.006208))
# (b)2.8 / 2.4
exp(6.492405 + (-0.026865) * 2.8 + (0.021836) * 2.4 + 2.8 * 2.4 * (-0.006208))
#Task 9
ggplot(data = lexdec.sub,
mapping = aes(x = Frequency, y = RT)) +
geom_point(color = "grey40", size = 3, alpha = 0.7) +
geom_smooth(method = "lm", se = F, color = "red", lwd = 1.5) +
labs(title = "Correlation between Reaction Time and Frequency",
caption = "Frequency and Reaction time are log-transformed",
x = "Frequency", y = "Reaction Time") + theme_bw()
#Task 10
val = data.frame(Frequency = seq(from = 2, to = 3, by = 0.1), FamilySize = seq(from = 0.5, to = 1.5, by = 0.1))
exp(predict(object = lexdec.lm3, newdata = val))
library(languageR)
#TASKI
#exclude the outliers of RT and Frequency at the same time
lexdec.sub=subset(lexdec, RT<=mean(RT)+2*sd(RT)&RT>=mean(RT)-2*sd(RT)&
Frequency<=mean(Frequency)+2*sd(Frequency)&Frequency>=mean(Frequency)-2*sd(Frequency))
#TASKII
#(a)draw the density plot to test if it's normally distributed
plot(density(lexdec.sub$RT), main="RT non-normal distribution;Right Skewness")
abline(v=mean(lexdec.sub$RT),col="blue",lwd=1.5)
abline(v=median(lexdec.sub$RT),col="red",lwd=1.5)
plot(density(lexdec.sub$Frequency), main="Frequency near-normal distribution")
abline(v=mean(lexdec.sub$Frequency),col="blue",lwd=1.5)
abline(v=median(lexdec.sub$Frequency),col="red",lwd=1.5)
#(b)generate a scatter plot to test if linearity and homoscedasticity are violated
plot(RT~Frequency,data=lexdec.sub, main="RT-Frequency Correlation in lexdec.sub",
xlab="log-transformed reaction times",ylab="log-transformed word frequency")
#TASKIII
lexdec.lm=lm(formula=RT~Frequency,data=lexdec.sub)
summary(lexdec.lm)
#TASKV
#Frequency=4.3
exp(6.523106+4.3*-0.035142)
#Frequency=5
exp(6.523106+5*-0.035142)
#Frequency=7.2
exp(6.523106+7.2*-0.035142)
#PARTII
#TASKVI
lexdec.lm2=lm(formula=RT~Frequency+FamilySize,data=lexdec.sub)
summary(lexdec.lm2)
#APA format:
#TASKVII
lexdec.lm3=lm(formula=RT~Frequency*FamilySize,data=lexdec.sub)
summary(lexdec.lm3)
#TASKVIII
#(a)Frequency=3.5 and FamilySize=1.3
exp(6.492405+3.5*-0.026865+1.3*0.021836+3.5*1.3*-0.006208)
#(b)Frequency=2.8 and FamilySize=2.4
exp(6.492405+2.8*-0.026865+2.4*0.021836+2.8*2.4*-0.006208)
#Bonus
#TASKIX
#generate a scatter plot
library(ggplot2)
ggplot(data=lexdec.sub,aes(x=RT,y=Frequency))+geom_point(color="grey40",size=3,alpha=0.7)+
geom_smooth(method="lm",se=F,color="red",lwd=1.5)+labs(title="RT-Frequency correlation in lexdec.sub",
x="log- transformed reaction times",
y="log-transformed word frequency")+theme_bw()
#TASKX
#use predict() function to generate predicted RTs
com.val=data.frame(Frequency=seq(from=2,to=3,by=0.1),FamilySize=seq(from=0.5,to=1.5,by=0.1))
rt.pred=predict(object=lexdec.lm3,newdata=com.val)
rt.pred
library(languageR)
head(lexdec)
#Task I
mean.rt = mean(lexdec$RT)
sd.rt = sd(lexdec$RT)
mean.fre = mean(lexdec$Frequency)
sd.fre = sd(lexdec$Frequency)
#Exclude outlier
lexdec.sub = subset(lexdec, RT < 2 * sd.rt + mean.rt & RT > mean.rt - 2 * sd.rt
& Frequency < 2 * sd.fre + mean.fre & Frequency > mean.fre - 2 * sd.fre)
#Task II
#a
plot(density(lexdec.sub$RT), main = "Reaction time density",
xlab = "Reaction Time")
plot(density(lexdec.sub$Frequency), main = "Frequency density",
xlab = "Frequency")
#b
library(ggplot2)
ggplot(data = lexdec.sub, mapping = aes(x = RT , y = Frequency)) +
geom_point(size = 1, alpha = 0.5, color = "gray60")+
labs(title = "RT ~ Frequency") +
theme_bw()
#Task III
lexdec.lm = lm(formula = RT ~ Frequency, data = lexdec.sub)
summary(lexdec.lm)
#Task V
exp(6.5231 + (4.3 * -0.0351))
# 585.3266
exp(6.5231 + (5 * -0.0351))
# 571.1204
exp(6.5231 + (7.2 * -0.0351))
# 528.6782
#Task VI
lexdec.lm2 = lm(formula = RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
(0.04195 - 0.04035) / 0.04035
# It explained 4% more variance.
#Task VII
lexdec.lm3 = lm(formula = RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
#Task VIII
exp(6.4924 + (-0.0268 * 3.5) + (0.0218 * 1.3) + (3.5 * 1.3 * -0.0062))
# 601.0812
exp(6.4924 + (-0.0268 * 2.8) + (0.0218 * 2.4) + (2.8 * 2.4 * -0.0062))
# 618.9447
library(languageR)
head(lexdec)
#Part I
#Task I
rt.mean = mean(lexdec$RT)
rt.sd = sd(lexdec$RT)
frequency.mean = mean(lexdec$Frequency)
frequency.sd = sd(lexdec$Frequency)
lexdec.sub = subset(lexdec, RT > rt.mean - 2 * rt.sd & RT < rt.mean + 2 * rt.sd &
Frequency > frequency.mean - 2 * frequency.sd & Frequency < frequency.mean + 2 * frequency.sd)
#Task II
#a
rt.den = density(lexdec.sub$RT)
plot(rt.den, main = "Distribution of Reaction Time")
frequency.den = density(lexdec.sub$Frequency)
plot(frequency.den, main = "Distribution of Frequency")
#b
cor.test(lexdec.sub$RT, lexdec.sub$Frequency)
plot(lexdec.sub$RT, lexdec.sub$Frequency, main = "Reaction Time ~ Frequency",
xlab = "Reaction Time", ylab = "Frequency")
abline(lm(lexdec.sub$Frequency ~ lexdec.sub$RT, data = lexdec.sub), col = "red")
#Task III
lexdec.lm = lm(formula = RT ~ Frequency, data = lexdec.sub)
summary(lexdec.lm)
#Task V
6.523106 + 4.3*-0.035142
6.523106 + 5*-0.035142
6.523106 + 7.2*-0.035142
exp(c(6.523106 + 4.3*-0.035142, 6.523106 + 5*-0.035142, 6.523106 + 7.2*-0.035142))
#Part II
#Task VI
lexdec.lm2 = lm(RT ~ Frequency + FamilySize, data = lexdec.sub)
summary(lexdec.lm2)
#Task VII
lexdec.lm3 = lm(RT ~ Frequency * FamilySize, data = lexdec.sub)
summary(lexdec.lm3)
#Task VIII
6.492405 + 3.5 * -0.026865 + 1.3 * 0.021836 + 3.5 * 1.3 * -0.006208
6.492405 + 2.8 * -0.026865 + 2.4 * 0.021836 + 2.8 * 2.4 * -0.006208
exp(c(6.492405 + 3.5 * -0.026865 + 1.3 * 0.021836 + 3.5 * 1.3 * -0.006208, 6.492405 + 2.8 * -0.026865 + 2.4 * 0.021836 + 2.8 * 2.4 * -0.006208))
59.45-54.75
