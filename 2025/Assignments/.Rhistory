# Part I
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/refs/heads/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
Myers.sample
# Task 1
# using subset() to extract Reaction Time (RT) which is higher than zero and
# 250, which excludes RT equals to zero or lower than 250 from Myers.sample
Myers.sub = subset(Myers.sample, RT > 0 & RT > 250)
# To convert values into SDs, first, log-transformed values are subtracted by
# the mean. Secondly, the deviations is divided by the standard deviation
Myers.sub$logRT.sd = (Myers.sub$logRT - logRT.mean) / logRT.sqrt.sd
# get the values which are bigger than -2 AND lower than 2 in order to exclude
# outliers
Myers.sd2 = subset(Myers.sub, Myers.sub$logRT.sd >= -2 & Myers.sub$logRT.sd <= 2)
# using log() to log-transform RT in Myers.sub
Myers.sub$logRT = log(Myers.sub$RT)
# get the mean of log-transformed values for standard deviation
logRT.mean = sum(Myers.sub$logRT) / length(Myers.sub$logRT)
# calculate the differences between each value and the mean
logRT.diff = Myers.sub$logRT - logRT.mean
# square the sum of deviations and divide it by the number of observations - 1,
# and get the square root of the result
logRT.sqrt.sd = sqrt(sum(logRT.diff ^ 2) / (length(logRT.diff) - 1))
# To convert values into SDs, first, log-transformed values are subtracted by
# the mean. Secondly, the deviations is divided by the standard deviation
Myers.sub$logRT.sd = (Myers.sub$logRT - logRT.mean) / logRT.sqrt.sd
# Task 3
# get the values which are bigger than -2 AND lower than 2 in order to exclude
# outliers
Myers.sd2 = subset(Myers.sub, Myers.sub$logRT.sd >= -2 & Myers.sub$logRT.sd <= 2)
# Task 4
# set the parameters vec1 and vec2 of the function trialRangeMeanRT
trialRangeMeanRT = function(vec1, vec2){
# extract values from TrialOrder in Myers.sd2,and check whether the values
# extracted from TrialOrder is in vec1
subset1 = subset(Myers.sd2, Myers.sd2$TrialOrder %in% vec1)
# calculate the mean of the RT values extracted from subset1
subset1.mean = mean(subset1$RT)
# extract values from TrialOrder in Myers.sd2, and check whether the values
# extracted from TrialOrder is in vec2
subset2 = subset(Myers.sd2, Myers.sd2$TrialOrder %in% vec2)
# calculate the mean of the RT values extracted from subset1
subset2.mean = mean(subset2$RT)
# print the output
print(paste("The mean RT of the two trial order ranges is ", subset1.mean,
" milliseconds and ",  subset2.mean, " milliseconds.", sep = ""))
}
# set the vec1 and vec2 as a trial order ranges
#The mean RT of the two trial order ranges is 1696.2625 milliseconds
# and 1567.21772151899 milliseconds.
trialRangeMeanRT(vec1 = 200:300, vec2 = 400:500)
# Yes, the difference in mean of reaction times shows satiation effect because
# the reaction times of 200th to 300th trials are longer than those of 400th to
# 500th trials. This shows that participants' acceptability becomes higher in the
# later experiment.
# set the vec1 and vec2 as a trial order ranges
# The mean RT of the two trial order ranges is 1208.8045112782 milliseconds
# and 1250.90930787589 milliseconds.
trialRangeMeanRT(vec1 = 900:1000, vec2 = 2900:3000)
# get the mean of logRT.sd
logRT.sd.mean = mean(logRT.sd)
#ChatGPT is used for clarifying R syntax errors and refining comment lines
#all codes of final version are reviewed and tested by myself
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
# 1.exclude an RT of 0 and an RT equal to or shorter than 250 ms
Myers.sub= subset(Myers.sample, RT> 250)
# 2.make log transformation and convert into SDs
#convert into log
Myers.sub$logRT= log(Myers.sub$RT)
#calculate mean and SD
Myers.logrt.mean= mean(Myers.sub$logRT)
Myers.logrt.sd= sd(Myers.sub$logRT)
#standardization logRT (aka. z-score)
Myers.sub$logRT.sd= (Myers.sub$logRT - Myers.logrt.mean) / Myers.logrt.sd
#I have a question: if not restricted by the assignment, can I name the
#   variable as Myers.sub.logrt.zscore? bcz I initially thought
#   "Myers.logrt.sd" and "Myers.sub$logRT.sd" were both SD.
# 3.exclude logRT.sd beyond Â±2
#remove outliers
Myers.sd2= subset(Myers.sub, logRT.sd >= -2 & logRT.sd <= 2)
# 4.write a function trialRangeMeanRT for calculating the mean RT
trialRangeMeanRT= function(range1, range2){
#use subset with %in% to retrieve TrialOrder rows in the specified range
#subset(name of data frame, column %in% vector of values)
Myers.subset1= subset(Myers.sd2, TrialOrder %in% range1)
#calculate mean RT for the first subset
Myers.mean1= mean(Myers.subset1$RT)
#round the mean to avoid too long output
Myers.round1= round(Myers.mean1, digits=2)
#repeat codes for the second subset and another range
Myers.subset2= subset(Myers.sd2, TrialOrder %in% range2)
Myers.mean2= mean(Myers.subset2$RT)
Myers.round2= round(Myers.mean2, digits=2)
print(paste("The mean RT of the two trial order ranges is", Myers.round1,
"milliseconds and", Myers.round2, "milliseconds."))
}
# 5.(1) 200:300 vs. 400:500 and (2) 900:1000 vs. 2900:3000, and explain
#   whether the output show a satiation effect, and why
#the first comparison
trialRangeMeanRT(200:300, 400:500)
#the second comparison
trialRangeMeanRT(900:1000, 2900:3000)
# 6.calculate the proportion below -1.5SD in sample and normal distribution
#calculate the proportion below -1.5SD in normal distribution
norm.prop= pnorm(q= -1.5)
#calculate the proportion below -1.5SD in sample distribution
Myers.sd2.logrt.sd.prop= mean(Myers.sd2$logRT.sd < -1.5)
#Explanation:
norm.prop
Myers.sd2.logrt.sd.prop
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/refs/heads/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
# 1
Myers.sub = subset(Myers.sample, RT > 250)
# 2
Myers.sub$logRT = log(Myers.sub$RT)
Myers.sub$logRT.sd = (Myers.sub$logRT - mean(Myers.sub$logRT)) / sd(Myers.sub$logRT)
# 3
Myers.sd2 = subset(Myers.sub, logRT.sd>= -2 & logRT.sd <= 2)
# 4
trialRangeMeanRT(200:300,400:500) #For this group, it doesn't show satiation effect because the response time for 400:500 is actually shorter than 200:300.
trialRangeMeanRT(900:1000,2900:3000)# For this group, it does show the satiation effect because the response time for 2900:3000 is actually longer than 900:1000.
# 6
norm.prop
Myers.sd2.prop
norm.prop = pnorm(q = -1.5)
Myers.sd2.prop = sum(Myers.sd2$logRT.sd < -1.5) / length(Myers.sd2$RT)
# Since the proportion of Myers.sd2 is smaller than normal distribution, it isn't normally distributed. And the lower tail is shorter than usual.
Myers.sd2.prop
# Part I
# Task 1
library(languageR)
head(durationsOnt)
?durationsOnt
# calculate the number of female and male based on "Sex" in durationsOnt by using
# xtab()
xtabs(formula = ~ Sex, data = durationsOnt)
# Task 2
# using table() to convert data frame "YearOfBirth" in "durationsOnt" to be
# a table
yearofbirth.table = table(durationsOnt$YearOfBirth)
# reorder the number of "YearOfBirth" from high to low (decreasing) by using order()
yearofbirth.ord = yearofbirth.table[order(yearofbirth.table, decreasing = T)]
# generate a bar plot, set the values of y-axis with yearofbirth.ord, set the
# y limit from 0 to 15, set the names of ylab and xlab, set the type of axis
barplot(height = yearofbirth.ord, main = "The Number of Dutch Speakers born in AD Years",
ylab = "The Number of Spearkers", xlab = "AD Year", ylim = c(0, 15),
las = 2)
# show the year with the highest number of speakers
yearofbirth.ord[1]
# using ifelse() to set the filter. Those higher than / equal to the median are
# "Old", while, those lower than the median are "Young"
durationsOnt$Generation =
ifelse(test = durationsOnt$YearOfBirth >= median(durationsOnt$YearOfBirth),
yes = "Old", no = "Young")
# get the columns "YearOfBirth" and "Generation" to show the output
durationsOnt[c("YearOfBirth", "Generation")]
# calculate the mean of the speech rate of "Old" and "Young" by using aggregate,
# and compare two types of speech rate
aggregate(SpeechRate ~ Generation, FUN = mean, data = durationsOnt)
# set the space with one column and 2 rows
par(mfrow = c(2, 1))
# extract the rows of "Old" from "Generation" column of durationsOnt data frame
old = subset(durationsOnt, Generation == "Old")
# get the density of the speech rate of old generation
old.den = density(old$SpeechRate)
# generate the density plot of the speech rate of old generation
plot(old.den, main = "Density of Old Speakers' Speech Rate")
# get the mean of old generation speech rate
old.mean = mean(old$SpeechRate)
# get the standard deviation of old generation speech rate
old.sd = sd(old$SpeechRate)
# add the red line to represent 2 standard deviation from the mean
abline(v = old.mean + 2 * old.sd, col = "red", lwd = 1.5)
# add the red line to represent -2 standard deviation from the mean
abline(v = old.mean - 2 * old.sd, col = "red", lwd = 1.5)
# extract the rows of "Young" from "Generation" column of durationsOnt data frame
young = subset(durationsOnt, Generation == "Young")
# get the density of the speech rate of young generation
young.den = density(young$SpeechRate)
# generate the density plot of the speech rate of young generation
plot(young.den, main = "Density of Young Speakers' Speech Rate")
# get the mean of young generation speech rate
young.mean = mean(young$SpeechRate)
# get the standard deviation of young generation speech rate
young.sd = sd(young$SpeechRate)
# add the red line to represent 2 standard deviation from the mean
abline(v = young.mean + 2 * young.sd, col = "red", lwd = 1.5)
# add the red line to represent -2 standard deviation from the mean
abline(v = young.mean - 2 * young.sd, col = "red", lwd = 1.5)
# reset the space with one row and one column
par(mfrow = c(1, 1))
# Part I
# Task 1
library(languageR)
head(durationsOnt)
?durationsOnt
# calculate the number of female and male based on "Sex" in durationsOnt by using
# xtab()
xtabs(formula = ~ Sex, data = durationsOnt)
# Task 2
# using table() to convert data frame "YearOfBirth" in "durationsOnt" to be
# a table
yearofbirth.table = table(durationsOnt$YearOfBirth)
# reorder the number of "YearOfBirth" from high to low (decreasing) by using order()
yearofbirth.ord = yearofbirth.table[order(yearofbirth.table, decreasing = T)]
# generate a bar plot, set the values of y-axis with yearofbirth.ord, set the
# y limit from 0 to 15, set the names of ylab and xlab, set the type of axis
barplot(height = yearofbirth.ord, main = "The Number of Dutch Speakers born in AD Years",
ylab = "The Number of Spearkers", xlab = "AD Year", ylim = c(0, 15),
las = 2)
# show the year with the highest number of speakers
yearofbirth.ord[1]
# Task 3
# using ifelse() to set the filter. Those higher than / equal to the median are
# "Old", while, those lower than the median are "Young"
durationsOnt$Generation =
ifelse(test = durationsOnt$YearOfBirth >= median(durationsOnt$YearOfBirth),
yes = "Old", no = "Young")
# get the columns "YearOfBirth" and "Generation" to show the output
durationsOnt[c("YearOfBirth", "Generation")]
# 1.count the number of male and female with one line of code
table(durationsOnt$Sex)
# 2.draw a bar plot of the number of speakers based on year
#convert YearOfBirth column to a table
dur.year.table= table(durationsOnt$YearOfBirth)
#reorder the table by frequency in decreasing order
dur.year.table.ord= order(dur.year.table, decreasing= T)
dur.year.table2= dur.year.table[dur.year.table.ord]
#generate a bar plot
barplot(height= dur.year.table2,
main= "Number of Dutch Speakers by Year of Birth",
xlab= "Year", ylab= "Number", ylim= c(0,15), las= 2)
#show the year with the highest number of speakers
names(dur.year.table2)[1]
names(dur.year.table2)[1]
dur.year.table2[1]
# 3.add a variable "Generation" based on the median of year to mark speakers
#use ifelse() to classify speakers based on whether year is below or above
# the median
durationsOnt$Generation=
ifelse(test= (durationsOnt$YearOfBirth) >= median(durationsOnt$YearOfBirth),
yes= "Young", no= "Old")
#verify the classification
head(durationsOnt[, c("YearOfBirth", "Generation")])
# 3.add a variable "Generation" based on the median of year to mark speakers
#use ifelse() to classify speakers based on whether year is below or above
# the median
durationsOnt$Generation=
ifelse(test= (durationsOnt$YearOfBirth) >= median(durationsOnt$YearOfBirth),
yes= "Young", no= "Old")
#verify the classification
head(durationsOnt[, c("YearOfBirth", "Generation")])
# 4.show the average speech rate for older and younger speakers respectively
#calculate the average speech rate for each generation group
aggregate(x= SpeechRate ~ Generation, FUN= mean, data= durationsOnt)
# 4.show the average speech rate for older and younger speakers respectively
#calculate the average speech rate for each generation group
aggregate(x= SpeechRate ~ Generation, FUN= mean, data= durationsOnt)
#Findings:
# older speakers: 5.236210
# younger speakers: 5.816525
# 5.generate a density plot with speech rate of older and younger speakers
#   add line of mean and Â±2SD
#color scheme: red for old speakers, blue for young speakers
#classify speech rate by generation
old.speechrate= subset(durationsOnt, Generation == "Old")$SpeechRate
young.speechrate= subset(durationsOnt, Generation == "Young")$SpeechRate
#calculate mean, SD, and density of speech rate for old and young speakers
old.mean= mean(old.speechrate)
old.sd= sd(old.speechrate)
old.den= density(old.speechrate)
young.mean= mean(young.speechrate)
young.sd= sd(young.speechrate)
young.den= density(young.speechrate)
#generate plot density curves for old (red) and young (blue) speakers
plot(old.den, main= "Density of Speech Rate by Generation
\n(red = Old, blue = Young)",
xlab= "Speech Rate", ylab= "", col= "red", lwd= 1.5)
lines(young.den, col= "blue", lwd= 1.5)
#add lines of mean (dashed) and SD (dotted) for each group
abline(v= old.mean, col= "darkred", lwd= 1.5, lty= 2)
abline(v= old.mean + 2*old.sd, col= "pink", lwd= 1.5, lty= 3)
abline(v= old.mean - 2*old.sd, col= "pink", lwd= 1.5, lty= 3)
abline(v= young.mean, col= "darkblue", lwd= 1.5, lty= 2)
abline(v= young.mean + 2*young.sd, col= "lightblue", lwd= 1.5, lty= 3)
abline(v= young.mean - 2*young.sd, col= "lightblue", lwd= 1.5, lty= 3)
# Part I
# Task 1
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/refs/heads/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
# extract the valid data which reaction time is higher than 200 ms
val = subset(Myers.sample, RT > 200)
# Task 2
# log-transform the reaction time in the valid data
val.log = log(val$RT)
# reorder the reaction time from low to high
val.ord = val.log[order(val.log, decreasing = FALSE)]
# calculate the position of the boundary of 25% in reordered valid reaction time
length(val.ord) * 0.25 # 3544.5 (the position between 3544 and 3545)
# Preparation work
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/refs/heads/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
# Part I
# Task 1 - Probably needs no explanation
Myers.sub = subset(Myers.sample, RT > 200)
# Task 2
# Log-transform RT first
Myers.sub$logRT = log(Myers.sub$RT)
# Order the entire data frame by logRT in ascending order
logRT.ord = order(Myers.sub$logRT)
Myers.sub.ord = Myers.sub[logRT.ord,]
# Get the sample size (i.e., the total number of data points or observations)
Myers.n = nrow(Myers.sub.ord)
nrow(Myers.n)
Myers.n
Myers.n / 4
summary(val.log) # 6.590
# In order to get the 25% boundary which is between the values of position 3544
# and 3545, add the value of position 3544 and 3545, which then divide by 2
(val.ord[3544] + val.ord[3545]) / 2 #  6.590301
# use random seed # 1111
set.seed(1111)
# sampling 1000 values from normal distribution with the mean and the standard
# deviation of log-transformed reaction time
nums = rnorm(1000, mean = mean(val.log), sd = sd(val.log))
# To calculate the proportion of sampled values lower than the boundary(6.590301),
# sum the number of values which are equal or lower than 6.590301, and then
# divide by the number of values in "nums"
sum(nums <= 6.590301) / length(nums) #  0.262
# Task 4
# The proportion (0.262) calculated in
compNormSamp(val.ord)
# Task 1
# First, extract the data of 1st Session from valid data set
session1 = subset(val, Session == 1)
# Then, generate the plot with "TrialOrder" at x-axis, and "RT" at y-axis
plot(RT ~ TrialOrder , data = session1,
# name the title of the plot, x-axis, y-axis, and the limit of x-axis
# and y-axis
main = "Correlation & Satiation Effect in Session 1",
xlab = "Trial Order", ylab = "Reaction Time", xlim = c(0, 1600),
ylim = c(0, 4500))
library(ggplot2)
# Using ggplot() to generate the plot showing the correlation between trial order
# and reaction time. First, the data which is going to explore is "val(the valid
# observation in Myers.sample), then mapping the x-aixs to TrialOrder" and y-axis
# to RT.
ggplot(data = val, mapping = aes(x = TrialOrder, y = RT)) +
# Second, mapping the color of points in session and the transparency
# is 0.1.
geom_point(mapping = aes(color = Session), alpha = 0.1) +
# Third, generate grid panels within a single ggplot, separating the
# the data based on the variable "Session", and each panel has its
# own x-axis range, but the range of y-axis is shared
facet_grid(. ~ Session, scales = "free_x") +
# Then, narrowing the space between 0 to the border of y, and set the
# limit ranging from 0 t0 4200
scale_y_continuous(expand = c(0.01, 0.01), limits = c(0, 4200)) +
# Ans, name the plot title, x-aixs, and y-axis.
labs(title = "Correlations & Satiation Effect in Sessions",
x = "Trial Order", y = "Reaction Time") +
# Finally, let the guide be deleted because it's not necessary, and set
# the theme of plot as black and white
guides(color = "none") + theme_bw()
#ChatGPT is used for clarifying R syntax errors and refining comment lines
#all codes of final version are reviewed and tested by myself
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
#Part 1:
# 1.exclude RT equals or being shorter than 200 ms
Myers.valid= subset(Myers.sample, RT> 200)
# 2.manually calculate the boundary between the 1st and the 2nd quartile of
#   log- transformed RTs
#convert RT to log to reduce skew
Myers.valid$logRT= log(Myers.valid$RT)
#get the ascending order data
Myers.logrt.ord= order(Myers.valid$logRT, decreasing= F)
Myers.logrt.sorted= Myers.valid$logRT[Myers.logrt.ord]
#calculate the boundary between the 1st and the 2nd quartile
Myers.logrt.q1.boundary= Myers.logrt.sorted[0.25* length(Myers.logrt.sorted)]
Myers.logrt.q1.boundary
0.25* length(Myers.logrt.sorted)
# 3.show the proportion of the sampled values lower than the boundary
#generate 1000 values from normal distribution using mean and sd of log RT
set.seed(1111)
Myers.logrt.num= rnorm(n= 1000, mean= mean(Myers.valid$logRT),
sd= sd(Myers.valid$logRT))
#calculate the proportion of sampled values lower than Q1 boundary
Myers.logrt.lower.prop= mean(Myers.logrt.num < Myers.logrt.q1.boundary)
Myers.logrt.lower.prop
#Part 2:
library(ggplot2)
# 1.generate plot with session 1 and explain the potential correlation and the
#   satiation effect
Myers.session1= subset(Myers.valid, Session == 1)
plot(main= "Trial Order vs. Reaction Time (Session 1)",
x= Myers.session1$TrialOrder, y= Myers.session1$RT,
xlab= "Trial Order", ylab= "Reaction Time (ms)", cex= 0.5)
# 1.There is a negative correlation between trial order and RT, meaning that
#   as trial order increases, RT tends to decrease.
# 2.There is no clear satiation effect observed. Instead of showing any
#   temporary increase in RT, participants become faster over time. There are
#   many points located below RT = 1000 between trials 1000~1500, indicating
#   continuous improvement or practice effects rather than satiation effect.
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/refs/heads/main/courseUtil.R")
Myers.sample = loadCourseCSV(2025, "3_Data", "Myers_2015_Sample.csv")
# Task 1
Myers.sub = subset(Myers.sample, RT > 200)
Myers.sub$LogRT = log(Myers.sub$RT)
Myers.sub.sorted = Myers.sub$LogRT[order(Myers.sub$LogRT, decreasing = F)]
pos = 1 + (length(Myers.sub.sorted) - 1) * 0.25
lower = floor(pos)
upper = ceiling(pos)
Myers.sub.q1 = Myers.sub.sorted[lower] + (pos - lower) * (Myers.sub.sorted[upper] - Myers.sub.sorted[lower])
# Sorry I use AI here because I didn't know how to calculate the boundary that seperates the first and second quartile base on the handout.
Myers.sub.q1
set.seed(1111)
Myers.samplevalues = rnorm(1000, mean = mean(Myers.sub$LogRT), sd = sd(Myers.sub$LogRT))
proportion_below.q1 = (sum(Myers.samplevalues < Myers.sub.q1) / length(Myers.samplevalues))
Myers.first.session = subset(Myers.sample, Session == 1)
plot(Myers.first.session$TrialOrder ~ Myers.first.session$RT, data = dursOnt.m,
main = "Trial Order vs Raw RT (Session 1)",
xlab = "Trial Order",
ylab = "Raw RT")
set.seed(1111)
Myers.samplevalues = rnorm(1000, mean = mean(Myers.sub$LogRT), sd = sd(Myers.sub$LogRT))
proportion_below.q1 = (sum(Myers.samplevalues < Myers.sub.q1) / length(Myers.samplevalues))
# Task 2
Myers.first.session = subset(Myers.sample, Session == 1)
plot(Myers.first.session$TrialOrder ~ Myers.first.session$RT, data = dursOnt.m,
main = "Trial Order vs Raw RT (Session 1)",
xlab = "Trial Order",
ylab = "Raw RT")
# As the trial order increases, the RT gradually decreases and the data points are more concentrated in the lower range, indicating a potential satiation effect. This suggests that participants respond faster as they become more familiar with the stimuli.
ggplot(data = Myers.sample,
mapping = aes(x = TrialOrder, y = RT )) +
geom_point(color = "grey40", size = 3, alpha = 0.7) +
facet_grid(. ~ Session, scales = "free_x") +
labs(title = "Trial Order vs Raw RT across Sessions",
x = "Trial Order", y = "Response Time") + theme_bw()
ggplot(data = Myers.sample,
mapping = aes(x = TrialOrder, y = RT )) +
geom_point(color = "grey40", size = 1, alpha = 0.7) +
facet_grid(. ~ Session, scales = "free_x") +
labs(title = "Trial Order vs Raw RT across Sessions",
x = "Trial Order", y = "Response Time") + theme_bw()
# RT in Session 2 decreases more gradually, indicating more stable responses and possible satiation.
# In Session 1, RT shows a steeper decline, suggesting a clear satiation effect as participants became familiar with the stimuli.
