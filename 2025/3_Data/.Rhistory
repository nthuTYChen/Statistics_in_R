?tensorflow
install_keras()
tensorflow::as_tensor("Hello World")
keras::install_keras()
library(keras)
install_keras(envname = "r-reticulate")
?install_keras
install_keras(envname = "r-reticulate", version = "2.12.*")
install_keras(envname = "r-reticulate", version = 2.12)
install_keras(envname = "r-reticulate", version = 2.14)
install_keras(envname = "r-reticulate", version = 2.1)
install_keras(envname = "r-reticulate", version = 2)
install_keras(envname = "r-reticulate", version = "2.13")
install_keras(envname = "r-reticulate", version = "2.12")
install_keras(envname = "r-reticulate", version = "nightly")
library(reticulate)
virtualenv_create("r-reticulate")
library(keras)
install_keras(envname = "r-reticulate")
library(keras)
install_keras(envname = "r-reticulate")
library(languageR)
head(durationsGe)
head(durationsOnt)
head(english)
head(lexdec)
head(english)
source("https://github.com/nthuTYChen/Statistics_in_R/blob/main/2024/Week1/replicate.R")
source("https://github.com/nthuTYChen/Statistics_in_R/blob/main/2024/Week1/replicate.R")
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/2024/Week1/replicate.R")
resourcesURL =
"https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/2004/Week1/"
df = read.csv(paste(resourcesURL, "dummyDataFrame.csv", sep = ""))
resourcesURL =
"https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/2024/Week1/"
df = read.csv(paste(resourcesURL, "dummyDataFrame.csv", sep = ""))
df
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(c(1, 2, 3, 4, 5, 6, 7), 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
sample(1:100, 3)
?sample
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:100, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
sample(1:4, 3, replace = T)
for(1:100) { print('hi!') }
for(i in 1:100) { print('hi!') }
c(1, 20, 30) > 80
if(c(1, 20, 30) > 80) { print('yes') }
for(i in 1:50) { sample(1:100, 3) }
for(i in 1:50) { print(sample(1:100, 3)) }
library(languageR)
head(verbs)
nrow(verbs)
x = c(1,1,1,1,1,2,2,3,3,3,3,3,3,3,3,3,4,4,5,5,5)
y = c(1,1,1,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,5,5)
plot(x, y)
abline(lm(y ~ x), col = "red")
set.seed(88)
x = rnorm(n = 100) * runif(n = 100)
x
x = rnorm(n = 100) * runif(n = 100)
x
set.seed(88)
x = rnorm(n = 100) * runif(n = 100)
x
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
x = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply x with noise to simulate a messier data distribution
x.noi = x * noise
# Check the range of our "sample" data distribution
range(x.noi)
# [1] 0.02286492 11.63822827
# Check the mean and SD of the "sample"
mean(x.noi) 	#
sd(x.noi) 	#
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = sd.mean)
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = nums.sd)
Now, we can generate the density plot of our sample distribution with nums and add the density information of nums (i.e., nums.d) obtained from a corresponding normal distribution to make our comparison, which is visualized in the figure below.
set.seed(88) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = nums, mean = nums.mean, sd = nums.sd)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
range.seq = seq(from = 0, to = 12, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi)) 	# Generate the density plot of our sample
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15)
# Add a purple curve line with a line width of 2, which shows the density
# information (range.seq.d) of each value in range.seq on the x-y plane
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15)
)
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
set.seed(87) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(86) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(85) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
set.seed(1) 	# Set the random seed no.88
# Sample 100 values from a normal distribution (mean = 10, sd = 2)
nums = rnorm(n = 100, mean = 10, sd = 2)
# Sample 100 values from a uniform distribution (between 0 and 1)
noise = runif(n = 100)
# Multiply nums with noise to simulate a messier data distribution
nums.noi = nums * noise
# Check the range of our "sample" data distribution
range(nums.noi)
# [1] 0.02286492 11.63822827
# Get the mean and SD of the "sample"
nums.mean = mean(nums.noi) 	# 4.60009
nums.sd = sd(nums.noi) 		# 3.102307
# Create a sequence of numeric values ranging from 0 to 12 separated by 0.01
# to cover the upper and lower boundary in our "sample" distribution
range.seq = seq(from = -5, to = 15, by = 0.01)
# Calculate the density of every single value in range.seq in a normal
# distribution of the same mean and SD using dnorm(), so we can visualize
# our theoretical distribution later.
range.seq.d = dnorm(x = range.seq, mean = nums.mean, sd = nums.sd)
plot(density(nums.noi), xlim = c(-5, 15), ylim = c(0, 0.15),
main = "Sample vs. Theoretical Distribution")
lines(x = range.seq, y = range.seq.d, col = "purple", lwd = 2)
qqnorm(nums.noi, main="Normal Q-Q Plot: nums.noi")
qqline(nums.noi, col="red")	# Add a line of "perfect correlation"
library(tidyverse)
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/cou
rseUtil.R")
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
wordRT = tibble(loadCourseCSV(year = 2024, topic = "3_Data", file = "wordRT.csv"))
wordRT
?gather
wordRT %>% gather(Word, "Gender", "RT")
stocks <- tibble(
time = as.Date("2009-01-01") + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
gather(stocks, "stock", "price", -time)
stocks %>% gather("stock", "price", -time)
sticks
stocks
wordRT %>% gather("Gender", "RT")
wordRT %>% gather("Gender", "RT", -Word)
wordRT %>% gather("Word", "Gender", "RT")
wordRT %>% pivot_longer(c("Gender", "RT"))
wordRT %>% pivot_longer(c("Male", "Female"))
wordRT %>% pivot_longer(c("Male", "Female"), names_to = "Gender", values_to = "RT")
jabberwocky.wd = loadCourseCSV(2024, "3_Data", "jabberwocky_words.txt")
head(jabberwocky.wd)
jabberwocky.wd = tibble(loadCourseCSV(2024, "3_Data", "jabberwocky_words.txt"))
jabberwocky.wd %>% count(Word)
?count
jabberwocky.wd %>% count(Word, name = "Freq")
jabberwocky.wd %>% count(Word, name = "Freq", sort = T)
strs = c("This is not a long sentence.")
strs.token = strsplit(strs, " ")
strs.token
strs.token = unlist(strsplit(strs, " "))
strs.token
strs.token = strsplit(strs, " ")
strs.token[1]
strs.token[[1]]
strs.token[[1]][]
strs.token[[1]][1]
set.seed(100) # Set the random seed
# Create a for loop in which n starts with 1 and increases by 1 after each cycle.
# The loop stops after the end of a cycle in which n becomes 50.
for(n in 1:20) {
# Randomly sample one value from a normal distribution using rnorm().
# Since the distribution has a mean of 0 and an sd of 1, which are the default
# values for the corresponding parameters in rnorm(), you don't have to specify
# the two parameters in this line. The randomly selected value is stored as
# "val".
val = rnorm(n = 1)
print(val) # Just print out the random value in each cycle.
}
1/20
library(ggplot2)
?geom_boxplot()
setwd("D:/OneDrive - NTHU/Academic Works/NTHU/Courses/Language and Statistics in R/GitHub/Statistics_in_R/2024/3_Data")
# Introduction to parametric tests that deal with CONTINUOUS data
# Let's being with a z-test
# Research question: Assuming that the population of 3-year-olds has an average
# vocabulary size of 300 words that vary by 40 words on average, do the children of
# the same age from a family with a higher socio-economic status have a significantly
# larger vocabulary size?
# Critical "parameters" in a parametric tests
mean.pop = 300    # Assumed population mean
sd.pop = 40       # Assumed population variance (SD)
mean.sample = 320 # The sample mean of vocabulary size
n = 10            # The sample sizeL Only ten 3-year-old children
# Standard Error
se = 40 / sqrt(10)
# z-value (different from a z-score; see the Unit 4 handout)
z = (mean.sample - mean.pop) / se
# Our sample mean is higher than the assumed population mean, so we calculate
# the upper tail p value in a normal distribution of differences based on
# the z-value obtained above.
pnorm(q = z, lower.tail = F)
log10(10)
log(2.718281828459)
log10(1/10)
# Starting in this unit, we always start by loading this script I created for you,
# which load a function loadCourseCSV() to help retrieve data sets from my GitHub
# repository
source("https://raw.githubusercontent.com/nthuTYChen/Statistics_in_R/main/courseUtil.R")
# Working on the corpus/count data: Jabberwocky from Alice in Wonderland
# Load a list of individual word tokens
jabberwocky.wd = loadCourseCSV(2024, "3_Data", "jabberwocky_words.txt")
# The number of rows in this data frame represents the number of word tokens
# in the Jabberwocky corpus.
nrow(jabberwocky.wd)
# Use table() to generate a frequency table of the Word column of the corpus.
jabberwocky.table = table(jabberwocky.wd$Word)
# The frequency table shows the number of tokens of each word TYPE in the corpus.
head(jabberwocky.table)
# We can convert the frequency table into a data frame using as.data.frame().
# In the output, the column names in the frequency table are sorted into the
# column Var1, and the token frequencies into the column Freq.
jabberwocky.df = as.data.frame(jabberwocky.table)
head(jabberwocky.df)
# Replace the original column names ["Var1", "Freq"] with another vector
# ["Word", "Count"] to have more proper column names in the data frame.
colnames(jabberwocky.df) = c("Word", "Count")
# In this new data frame, each row represents an observation on a word type
# in the corpus and the token number of the word type.
nrow(jabberwocky.df)
# The sum of token frequencies is still equivalent to the original corpus size,
# namely the number of word tokens in the corpus.
sum(jabberwocky.df$Count)
# Apply the order() function to the Count column of the new data frame to get
# the number of rows sorted based on the Count values in decreasing order.
order(jabberwocky.df$Count, decreasing = T)
# The first row number in the above output is 71, and the 71st row in the
# data frame is the word type with the highest token frequency (the, 19 times)
jabberwocky.df[71,]
# The first row number in the above output is 2, and the 2nd row in the
# data frame is the word type with the second-highest token frequency (and, 14 times)
jabberwocky.df[2,]
# Save the re-ordered row numbers separately.
count.des.ord = order(jabberwocky.df$Count, decreasing = T)
# Use the re-ordered row numbers to sort the original data frame and get a re-ordered
# data frame.
jabberwocky.ord = jabberwocky.df[count.des.ord,]
# Get the last ten rows that represent the word type with the 10 lowest token
# frequency
tail(jabberwocky.ord, 10)
# Show the rows whose Cat column has an NA value.
jabberwocky.wordCat[cat.na,]
# Load another data frame in which each word type in Jabberwocky is marked with
# information regarding whether the word is a real word or not and whether it is
# a function word or a content word.
jabberwocky.wordCat = loadCourseCSV(2025, "3_Data", "jabberwocky_words_cat.csv")
# I could not identify the word category of some word types in the corpus,
# so in the Cat column, these word types have the value NA (= not applicable)
# is.na() checks if values of a vector is equal to NA and returns TRUEs and FALSES
# The result of checking the Cat column is saved to cat.na first.
cat.na = is.na(jabberwocky.wordCat$Cat)
# Sum all TRUEs to show how many NAs there are in Cat.
sum(cat.na) # 3
# Show the rows whose Cat column has an NA value.
jabberwocky.wordCat[cat.na,]
# Show the rows whose Cat colunm DOES NOT have an NA value.
# ! = Not; Not TRUE = FALSE, Not FALSE = TRUE
head(jabberwocky.wordCat[!cat.na,])
# Save all rows WITHOUT an NA value in the Cat column as a separate data frame.
jabberwocky.wordCat.noNA = jabberwocky.wordCat[!cat.na,]
# Merge the data frame with word frequency info and the data frame with word
# category and real/fake word info. Specify the "by" parameter, so the merge()
# function knows which column to refer to when merging data frames based on the
# same values across the two data frame.
jabberwocky.all = merge(jabberwocky.ord, jabberwocky.wordCat.noNA, by = "Word")
# There are 88 word types after merger because jabberwocky.wordCat.noNA does not
# include the three rows with an NA value in the Cat column
nrow(jabberwocky.all)
# The original data frame with frequency information still has 91 word types
nrow(jabberwocky.ord)
# Use xtabs() to add values in Count based on whether a word type is real or not
# (N vs. Y)
xtabs(formula = Count ~ Real, data = jabberwocky.all)
# Use xtabs() to count the number of each levels in the Real column to know
# how many real/fake words there are in the data frame
xtabs(formula = ~ Real, data = jabberwocky.all)
# Use xtabs() to create a 2 x 2 contingency table, which shows how many
# combinations of different levels of Real and Cat (e.g., real content word,
# fake function word) in the data set.
jabberwocky.xtabs = xtabs(formula = ~ Real + Cat, data = jabberwocky.all)
# We can sum up all the values in a contingency table and get the number of
# word types; 88
jabberwocky.sum = sum(jabberwocky.xtabs)
# Divide the entire table by the sum to convert raw type frequencies into
# probabilities.
jabberwocky.prob = jabberwocky.xtabs / jabberwocky.sum
# Multiply all probabilities by 100 to get the percentages
jabberwocky.perc = jabberwocky.prob * 100
# Get the percentages and round them to the first decimal place.
jabberwocky.perc = round(jabberwocky.prob * 100, digit = 1)
# Get the percentages and round them to the first decimal place.
jabberwocky.perc
